#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å†·é—¨æŒ–æ˜å™¨é¢„æµ‹æ¨¡å‹é›† - ç§‘ç ”çº§å®Œæ•´å®ç°
ä¸“é—¨é’ˆå¯¹"æ€å¤šèµ”å°‘"ç­–ç•¥ä¸­è¢«å¿½è§†çš„å†·é—¨å°¾æ•°ç»„åˆæŒ–æ˜
"""

import numpy as np
import math
from collections import defaultdict, deque
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any, Set
from dataclasses import dataclass
from enum import Enum
import json
import statistics
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# æ•°æ®ç»“æ„å®šä¹‰
@dataclass
class ColdnessProfile:
    """å†·é—¨åº¦æ¡£æ¡ˆæ•°æ®ç»“æ„"""
    tail: int
    current_absence_length: int      # å½“å‰ç¼ºå¸­é•¿åº¦
    max_absence_length: int          # å†å²æœ€å¤§ç¼ºå¸­é•¿åº¦
    avg_absence_length: float        # å¹³å‡ç¼ºå¸­é•¿åº¦
    total_appearances: int           # æ€»å‡ºç°æ¬¡æ•°
    appearance_frequency: float      # å‡ºç°é¢‘ç‡
    coldness_index: float           # ç»¼åˆå†·é—¨æŒ‡æ•°
    revival_probability: float       # å¤å‡ºæ¦‚ç‡
    last_appearance_period: int      # ä¸Šæ¬¡å‡ºç°æœŸæ•°ç´¢å¼•

@dataclass
class RevivalSignal:
    """å¤å‡ºä¿¡å·æ•°æ®ç»“æ„"""
    tail: int
    signal_strength: float          # ä¿¡å·å¼ºåº¦ 0-1
    signal_type: str               # 'cyclic', 'compensation', 'pattern_break'
    expected_timing: int           # é¢„æœŸå¤å‡ºæ—¶æœº
    confidence: float              # ç½®ä¿¡åº¦
    supporting_evidence: List[str] # æ”¯æŒè¯æ®

class ColdnessLevel(Enum):
    """å†·é—¨ç¨‹åº¦ç­‰çº§"""
    EXTREMELY_COLD = 5    # æåº¦å†·é—¨
    VERY_COLD = 4        # éå¸¸å†·é—¨
    MODERATELY_COLD = 3  # ä¸­ç­‰å†·é—¨
    SLIGHTLY_COLD = 2    # è½»å¾®å†·é—¨
    NEUTRAL = 1          # ä¸­æ€§
    WARM = 0             # æ¸©çƒ­

class UnpopularDigger:
    """
    å†·é—¨æŒ–æ˜å™¨ - ç§‘ç ”çº§å®Œæ•´å®ç°
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å¤šç»´åº¦å†·é—¨åˆ†æç®—æ³•
    2. é•¿æœŸå†·é—¨è¿½è¸ªç³»ç»Ÿ
    3. å¤å‡ºæ—¶æœºé¢„æµ‹æ¨¡å‹
    4. åçƒ­é—¨ç­–ç•¥ç”Ÿæˆ
    5. åŠ¨æ€å†·é—¨åº¦è¯„ä¼°
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–å†·é—¨æŒ–æ˜å™¨"""
        self.config = config or self._get_default_config()
        
        # æ ¸å¿ƒåˆ†æç»„ä»¶
        self.coldness_analyzer = ColdnessAnalyzer()
        self.revival_predictor = RevivalPredictor()
        self.anti_hot_strategist = AntiHotStrategist()
        self.pattern_detector = ColdPatternDetector()
        
        # å†å²æ•°æ®å­˜å‚¨
        self.coldness_profiles = {}  # æ¯ä¸ªå°¾æ•°çš„å†·é—¨æ¡£æ¡ˆ
        self.revival_history = deque(maxlen=self.config['revival_history_window'])
        self.prediction_outcomes = deque(maxlen=self.config['outcome_tracking_window'])
        
        # å­¦ä¹ çŠ¶æ€
        self.total_predictions = 0
        self.successful_revivals = 0
        self.model_confidence = 0.5
        self.adaptation_rate = self.config['adaptation_rate']
        
        # å¤šæ—¶é—´å°ºåº¦åˆ†æçª—å£
        self.analysis_windows = {
            'immediate': deque(maxlen=5),      # æœ€è¿‘5æœŸ
            'short_term': deque(maxlen=15),    # çŸ­æœŸ15æœŸ
            'medium_term': deque(maxlen=40),   # ä¸­æœŸ40æœŸ
            'long_term': deque(maxlen=100),    # é•¿æœŸ100æœŸ
        }
        
        # å†·é—¨æŒ–æ˜ç­–ç•¥åº“
        self.digging_strategies = self._initialize_digging_strategies()
        
        print(f"ğŸ” å†·é—¨æŒ–æ˜å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - åˆ†æçª—å£: {len(self.analysis_windows)}ä¸ªæ—¶é—´å°ºåº¦")
        print(f"   - æŒ–æ˜ç­–ç•¥: {len(self.digging_strategies)}ç§")
        print(f"   - é€‚åº”æ€§å­¦ä¹ ç‡: {self.adaptation_rate}")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'revival_history_window': 200,
            'outcome_tracking_window': 100,
            'adaptation_rate': 0.12,
            'coldness_threshold': 0.7,
            'revival_confidence_threshold': 0.6,
            'max_absence_tracking': 50,
            'pattern_matching_sensitivity': 0.8,
            'anti_hot_aggressiveness': 0.75,
            'cyclic_analysis_depth': 3,
            'compensation_psychology_weight': 0.4,
            'pattern_break_weight': 0.35,
            'frequency_deviation_weight': 0.25,
        }
    
    def predict(self, candidate_tails: List[int], historical_context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åœ¨ç­›é€‰åçš„å€™é€‰å°¾æ•°ä¸­è¿›è¡Œå†·é—¨æŒ–æ˜é¢„æµ‹
        
        Args:
            candidate_tails: ç»è¿‡ä¸‰å¤§å®šå¾‹ç­›é€‰çš„å€™é€‰å°¾æ•°
            historical_context: å†å²ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        prediction_start_time = datetime.now()
        
        if not candidate_tails:
            return {
                'success': False,
                'recommended_tails': [],
                'confidence': 0.0,
                'message': 'no_candidate_tails_provided',
                'coldness_analysis': {}
            }
        
        if len(historical_context) < 10:
            return {
                'success': False,
                'recommended_tails': [],
                'confidence': 0.0,
                'message': 'insufficient_historical_data',
                'coldness_analysis': {}
            }
        
        print(f"ğŸ” å†·é—¨æŒ–æ˜å™¨å¼€å§‹åˆ†æ {len(candidate_tails)} ä¸ªå€™é€‰å°¾æ•°: {candidate_tails}")
        
        # æ›´æ–°æ‰€æœ‰åˆ†æçª—å£
        if historical_context:
            latest_period = historical_context[0]  # æœ€æ–°æœŸåœ¨å‰
            for window in self.analysis_windows.values():
                window.appendleft(latest_period)  # æ·»åŠ åˆ°å·¦è¾¹ï¼ˆæœ€æ–°ï¼‰
        
        # === æ›´æ–°å†·é—¨æ¡£æ¡ˆ ===
        self._update_coldness_profiles(historical_context)
        
        # === å€™é€‰å°¾æ•°å†·é—¨åº¦åˆ†æ ===
        candidate_coldness_analysis = {}
        for tail in candidate_tails:
            coldness_analysis = self.coldness_analyzer.analyze_tail_coldness(
                tail, historical_context, self.analysis_windows
            )
            candidate_coldness_analysis[tail] = coldness_analysis
        
        # === å¤å‡ºæ—¶æœºé¢„æµ‹ ===
        revival_predictions = {}
        for tail in candidate_tails:
            if tail in candidate_coldness_analysis:
                coldness_data = candidate_coldness_analysis[tail]
                revival_pred = self.revival_predictor.predict_revival_timing(
                    tail, coldness_data, historical_context
                )
                revival_predictions[tail] = revival_pred
        
        # === åçƒ­é—¨ç­–ç•¥åˆ†æ ===
        anti_hot_analysis = self.anti_hot_strategist.analyze_anti_hot_opportunities(
            candidate_tails, historical_context, candidate_coldness_analysis
        )
        
        # === å†·é—¨æ¨¡å¼æ£€æµ‹ ===
        pattern_analysis = self.pattern_detector.detect_cold_patterns(
            candidate_tails, historical_context, candidate_coldness_analysis
        )
        
        # === ç»¼åˆè¯„åˆ†ä¸æ¨èç”Ÿæˆ ===
        final_recommendations = self._generate_final_recommendations(
            candidate_tails, candidate_coldness_analysis, revival_predictions,
            anti_hot_analysis, pattern_analysis, historical_context
        )
        
        # æ›´æ–°å­¦ä¹ çŠ¶æ€
        self._update_learning_state(final_recommendations)
        
        # è®°å½•é¢„æµ‹å†å²
        prediction_record = {
            'timestamp': prediction_start_time,
            'candidate_tails': candidate_tails,
            'recommendations': final_recommendations,
            'coldness_analysis': candidate_coldness_analysis,
            'revival_predictions': revival_predictions,
            'anti_hot_analysis': anti_hot_analysis,
            'pattern_analysis': pattern_analysis
        }
        
        self.revival_history.append(prediction_record)
        
        prediction_duration = (datetime.now() - prediction_start_time).total_seconds()
        
        result = {
            'success': True,
            'model_name': 'UnpopularDigger',
            'recommended_tails': final_recommendations['recommended_tails'],
            'confidence': final_recommendations['confidence'],
            'coldness_analysis': candidate_coldness_analysis,
            'revival_signals': revival_predictions,
            'anti_hot_opportunities': anti_hot_analysis,
            'pattern_insights': pattern_analysis,
            'strategy_reasoning': final_recommendations['reasoning'],
            'prediction_quality': final_recommendations['quality_assessment'],
            'analysis_duration': prediction_duration,
            'total_candidates_analyzed': len(candidate_tails)
        }
        
        print(f"ğŸ” å†·é—¨æŒ–æ˜å®Œæˆï¼Œæ¨è {len(final_recommendations['recommended_tails'])} ä¸ªå†·é—¨å°¾æ•°")
        
        return result
    
    def _update_coldness_profiles(self, historical_context: List[Dict[str, Any]]):
        """æ›´æ–°æ‰€æœ‰å°¾æ•°çš„å†·é—¨æ¡£æ¡ˆ"""
        
        for tail in range(10):
            # è®¡ç®—å½“å‰ç¼ºå¸­é•¿åº¦
            current_absence = 0
            for i, period in enumerate(historical_context):
                if tail not in period.get('tails', []):
                    current_absence += 1
                else:
                    break
            
            # è®¡ç®—å†å²ç»Ÿè®¡
            total_appearances = 0
            absence_lengths = []
            current_streak = 0
            is_absent = True
            
            for period in reversed(historical_context):  # ä»æœ€æ—§åˆ°æœ€æ–°
                if tail in period.get('tails', []):
                    total_appearances += 1
                    if is_absent and current_streak > 0:
                        absence_lengths.append(current_streak)
                        current_streak = 0
                    is_absent = False
                else:
                    if not is_absent:
                        current_streak = 1
                        is_absent = True
                    else:
                        current_streak += 1
            
            # æ·»åŠ å½“å‰ç¼ºå¸­æœŸ
            if is_absent and current_streak > 0:
                absence_lengths.append(current_streak)
            
            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            max_absence = max(absence_lengths) if absence_lengths else current_absence
            avg_absence = np.mean(absence_lengths) if absence_lengths else current_absence
            appearance_freq = total_appearances / len(historical_context) if historical_context else 0
            
            # æ‰¾åˆ°ä¸Šæ¬¡å‡ºç°ä½ç½®
            last_appearance_period = -1
            for i, period in enumerate(historical_context):
                if tail in period.get('tails', []):
                    last_appearance_period = i
                    break
            
            # è®¡ç®—å†·é—¨æŒ‡æ•°
            coldness_index = self._calculate_coldness_index(
                current_absence, max_absence, avg_absence, appearance_freq, len(historical_context)
            )
            
            # è®¡ç®—å¤å‡ºæ¦‚ç‡
            revival_probability = self._calculate_revival_probability(
                current_absence, avg_absence, appearance_freq
            )
            
            # æ›´æ–°æ¡£æ¡ˆ
            self.coldness_profiles[tail] = ColdnessProfile(
                tail=tail,
                current_absence_length=current_absence,
                max_absence_length=max_absence,
                avg_absence_length=avg_absence,
                total_appearances=total_appearances,
                appearance_frequency=appearance_freq,
                coldness_index=coldness_index,
                revival_probability=revival_probability,
                last_appearance_period=last_appearance_period
            )
    
    def _calculate_coldness_index(self, current_absence: int, max_absence: int, 
                                 avg_absence: float, appearance_freq: float, 
                                 total_periods: int) -> float:
        """è®¡ç®—ç»¼åˆå†·é—¨æŒ‡æ•°"""
        
        # å½“å‰ç¼ºå¸­æƒé‡
        absence_weight = min(1.0, current_absence / 20.0) * 0.4
        
        # é¢‘ç‡æƒé‡ï¼ˆä½é¢‘ç‡ = å†·é—¨ï¼‰
        frequency_weight = (1.0 - appearance_freq) * 0.35
        
        # å¼‚å¸¸ç¼ºå¸­æƒé‡
        if avg_absence > 0:
            abnormal_absence = max(0, (current_absence - avg_absence) / avg_absence)
            abnormal_weight = min(1.0, abnormal_absence) * 0.25
        else:
            abnormal_weight = 0.5
        
        coldness_index = absence_weight + frequency_weight + abnormal_weight
        return min(1.0, max(0.0, coldness_index))
    
    def _calculate_revival_probability(self, current_absence: int, 
                                     avg_absence: float, appearance_freq: float) -> float:
        """è®¡ç®—å¤å‡ºæ¦‚ç‡"""
        
        if avg_absence <= 0:
            return 0.5
        
        # åŸºäºå¹³å‡ç¼ºå¸­é•¿åº¦çš„æœŸæœ›å¤å‡ºæ¦‚ç‡
        expected_revival = min(1.0, current_absence / (avg_absence * 1.5))
        
        # åŸºäºå†å²é¢‘ç‡çš„åŸºç¡€æ¦‚ç‡
        base_probability = appearance_freq
        
        # è¡¥å¿æ•ˆåº”ï¼šç¼ºå¸­è¶Šä¹…ï¼Œå¤å‡ºæ¦‚ç‡è¶Šé«˜
        compensation_factor = min(1.0, current_absence / 15.0)
        
        # ç»¼åˆå¤å‡ºæ¦‚ç‡
        revival_prob = (expected_revival * 0.4 + base_probability * 0.3 + compensation_factor * 0.3)
        
        return min(0.95, max(0.05, revival_prob))
    
    def _generate_final_recommendations(self, candidate_tails: List[int], 
                                      coldness_analysis: Dict[int, Dict], 
                                      revival_predictions: Dict[int, Dict],
                                      anti_hot_analysis: Dict[str, Any], 
                                      pattern_analysis: Dict[str, Any],
                                      historical_context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæ¨è"""
        
        # ä¸ºæ¯ä¸ªå€™é€‰å°¾æ•°è®¡ç®—ç»¼åˆè¯„åˆ†
        tail_scores = {}
        
        for tail in candidate_tails:
            score_components = {
                'coldness_score': 0.0,
                'revival_score': 0.0,
                'anti_hot_score': 0.0,
                'pattern_score': 0.0
            }
            
            # å†·é—¨åº¦è¯„åˆ†
            if tail in coldness_analysis:
                coldness_data = coldness_analysis[tail]
                coldness_level = coldness_data.get('coldness_level', ColdnessLevel.NEUTRAL)
                
                coldness_mapping = {
                    ColdnessLevel.EXTREMELY_COLD: 1.0,
                    ColdnessLevel.VERY_COLD: 0.8,
                    ColdnessLevel.MODERATELY_COLD: 0.6,
                    ColdnessLevel.SLIGHTLY_COLD: 0.4,
                    ColdnessLevel.NEUTRAL: 0.2,
                    ColdnessLevel.WARM: 0.0
                }
                
                score_components['coldness_score'] = coldness_mapping.get(coldness_level, 0.2)
            
            # å¤å‡ºæ—¶æœºè¯„åˆ†
            if tail in revival_predictions:
                revival_data = revival_predictions[tail]
                revival_strength = revival_data.get('revival_strength', 0.0)
                timing_score = revival_data.get('timing_score', 0.0)
                
                score_components['revival_score'] = (revival_strength * 0.6 + timing_score * 0.4)
            
            # åçƒ­é—¨æœºä¼šè¯„åˆ†
            anti_hot_opportunities = anti_hot_analysis.get('tail_opportunities', {})
            if tail in anti_hot_opportunities:
                opportunity_data = anti_hot_opportunities[tail]
                score_components['anti_hot_score'] = opportunity_data.get('opportunity_strength', 0.0)
            
            # å†·é—¨æ¨¡å¼è¯„åˆ†
            pattern_signals = pattern_analysis.get('tail_pattern_signals', {})
            if tail in pattern_signals:
                pattern_data = pattern_signals[tail]
                score_components['pattern_score'] = pattern_data.get('pattern_strength', 0.0)
            
            # ç»¼åˆè¯„åˆ†
            weights = self.config
            total_score = (
                score_components['coldness_score'] * 0.35 +
                score_components['revival_score'] * 0.3 +
                score_components['anti_hot_score'] * 0.2 +
                score_components['pattern_score'] * 0.15
            )
            
            tail_scores[tail] = {
                'total_score': total_score,
                'components': score_components,
                'coldness_profile': self.coldness_profiles.get(tail)
            }
        
        # é€‰æ‹©è¯„åˆ†æœ€é«˜çš„å°¾æ•°
        if not tail_scores:
            return {
                'recommended_tails': [],
                'confidence': 0.0,
                'reasoning': 'no_valid_candidates',
                'quality_assessment': 'poor'
            }
        
        # æ’åºå¹¶é€‰æ‹©topå°¾æ•°
        sorted_tails = sorted(tail_scores.items(), key=lambda x: x[1]['total_score'], reverse=True)
        
        # åŠ¨æ€é€‰æ‹©æ¨èæ•°é‡
        recommendation_count = self._determine_recommendation_count(sorted_tails, candidate_tails)
        
        recommended_tails = [tail for tail, _ in sorted_tails[:recommendation_count]]
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_prediction_confidence(sorted_tails, anti_hot_analysis, pattern_analysis)
        
        # ç”Ÿæˆæ¨ç†è¯´æ˜
        reasoning = self._generate_reasoning(recommended_tails, tail_scores, coldness_analysis, revival_predictions)
        
        # è´¨é‡è¯„ä¼°
        quality = self._assess_prediction_quality(confidence, len(recommended_tails), tail_scores)
        
        return {
            'recommended_tails': recommended_tails,
            'confidence': confidence,
            'reasoning': reasoning,
            'quality_assessment': quality,
            'tail_scores': tail_scores,
            'selection_details': {
                'total_candidates': len(candidate_tails),
                'candidates_scored': len(tail_scores),
                'recommendation_count': recommendation_count,
                'top_score': sorted_tails[0][1]['total_score'] if sorted_tails else 0.0
            }
        }
    
    def _determine_recommendation_count(self, sorted_tails: List[Tuple], candidate_tails: List[int]) -> int:
        """åŠ¨æ€ç¡®å®šæ¨èæ•°é‡"""
        
        if not sorted_tails:
            return 0
        
        # åŸºäºè¯„åˆ†å·®å¼‚åŠ¨æ€è°ƒæ•´
        top_score = sorted_tails[0][1]['total_score']
        
        if top_score > 0.8:
            # æœ‰æ˜æ˜¾çš„é«˜åˆ†å†·é—¨å°¾æ•°
            return 1
        elif top_score > 0.6:
            # ä¸­ç­‰å†·é—¨ç¨‹åº¦ï¼Œå¯ä»¥æ¨è1-2ä¸ª
            count = 1
            if len(sorted_tails) > 1 and sorted_tails[1][1]['total_score'] > 0.5:
                count = 2
            return count
        else:
            # å†·é—¨ç¨‹åº¦ä¸€èˆ¬ï¼Œæœ€å¤šæ¨è2ä¸ª
            return min(2, len(sorted_tails))
    
    def _calculate_prediction_confidence(self, sorted_tails: List[Tuple], 
                                       anti_hot_analysis: Dict, pattern_analysis: Dict) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦"""
        
        if not sorted_tails:
            return 0.0
        
        confidence_factors = []
        
        # è¯„åˆ†è´¨é‡å› å­
        top_score = sorted_tails[0][1]['total_score']
        score_quality = min(1.0, top_score)
        confidence_factors.append(score_quality)
        
        # è¯„åˆ†ä¸€è‡´æ€§å› å­
        if len(sorted_tails) > 1:
            scores = [item[1]['total_score'] for item in sorted_tails]
            score_std = np.std(scores)
            consistency = max(0.0, 1.0 - score_std)
            confidence_factors.append(consistency)
        else:
            confidence_factors.append(0.8)
        
        # åçƒ­é—¨ä¿¡å·å¼ºåº¦
        anti_hot_strength = anti_hot_analysis.get('overall_strength', 0.5)
        confidence_factors.append(anti_hot_strength)
        
        # æ¨¡å¼ä¿¡å·å¼ºåº¦
        pattern_strength = pattern_analysis.get('overall_pattern_strength', 0.5)
        confidence_factors.append(pattern_strength)
        
        # å†å²æˆåŠŸç‡
        historical_success = self.successful_revivals / max(self.total_predictions, 1)
        confidence_factors.append(historical_success)
        
        # æ•°æ®å……è¶³æ€§
        data_sufficiency = min(1.0, len(self.revival_history) / 50.0)
        confidence_factors.append(data_sufficiency)
        
        # ç»¼åˆç½®ä¿¡åº¦
        overall_confidence = np.mean(confidence_factors)
        
        return min(0.95, max(0.05, overall_confidence))
    
    def _generate_reasoning(self, recommended_tails: List[int], tail_scores: Dict, 
                          coldness_analysis: Dict, revival_predictions: Dict) -> str:
        """ç”Ÿæˆæ¨ç†è¯´æ˜"""
        
        reasoning_parts = []
        
        if not recommended_tails:
            return "æ— æœ‰æ•ˆçš„å†·é—¨æŒ–æ˜æœºä¼š"
        
        reasoning_parts.append(f"ğŸ” å†·é—¨æŒ–æ˜æ¨è: {recommended_tails}")
        
        for tail in recommended_tails:
            if tail in tail_scores:
                score_data = tail_scores[tail]
                total_score = score_data['total_score']
                components = score_data['components']
                
                # åˆ†æä¸»è¦æ¨èåŸå› 
                max_component = max(components.items(), key=lambda x: x[1])
                reason_type = max_component[0]
                reason_strength = max_component[1]
                
                if reason_type == 'coldness_score':
                    reasoning_parts.append(f"å°¾æ•°{tail}: å†·é—¨åº¦é«˜({reason_strength:.2f})")
                elif reason_type == 'revival_score':
                    reasoning_parts.append(f"å°¾æ•°{tail}: å¤å‡ºæ—¶æœºåˆ°({reason_strength:.2f})")
                elif reason_type == 'anti_hot_score':
                    reasoning_parts.append(f"å°¾æ•°{tail}: åçƒ­é—¨æœºä¼š({reason_strength:.2f})")
                elif reason_type == 'pattern_score':
                    reasoning_parts.append(f"å°¾æ•°{tail}: å†·é—¨æ¨¡å¼ä¿¡å·({reason_strength:.2f})")
                
                # æ·»åŠ å†·é—¨æ¡£æ¡ˆä¿¡æ¯
                if tail in self.coldness_profiles:
                    profile = self.coldness_profiles[tail]
                    reasoning_parts.append(f"  ç¼ºå¸­{profile.current_absence_length}æœŸ, å†·é—¨æŒ‡æ•°{profile.coldness_index:.2f}")
        
        return " | ".join(reasoning_parts)
    
    def _assess_prediction_quality(self, confidence: float, recommendation_count: int, 
                                 tail_scores: Dict) -> str:
        """è¯„ä¼°é¢„æµ‹è´¨é‡"""
        
        if confidence > 0.8 and recommendation_count > 0:
            return "excellent"
        elif confidence > 0.7 and recommendation_count > 0:
            return "good"
        elif confidence > 0.6:
            return "moderate"
        elif confidence > 0.4:
            return "fair"
        else:
            return "poor"
    
    def _update_learning_state(self, recommendations: Dict):
        """æ›´æ–°å­¦ä¹ çŠ¶æ€"""
        
        self.total_predictions += 1
        
        # åŸºäºæ¨èè´¨é‡æ›´æ–°æ¨¡å‹ç½®ä¿¡åº¦
        quality = recommendations.get('quality_assessment', 'moderate')
        quality_scores = {
            'excellent': 0.9,
            'good': 0.75,
            'moderate': 0.6,
            'fair': 0.45,
            'poor': 0.3
        }
        
        quality_score = quality_scores.get(quality, 0.6)
        
        # æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–°
        self.model_confidence = (
            self.model_confidence * (1 - self.adaptation_rate) +
            quality_score * self.adaptation_rate
        )
        
        self.model_confidence = min(0.95, max(0.05, self.model_confidence))
    
    def learn_from_outcome(self, prediction_result: Dict[str, Any], 
                          actual_outcome: List[int]) -> Dict[str, Any]:
        """ä»ç»“æœä¸­å­¦ä¹ """
        
        recommended_tails = prediction_result.get('recommended_tails', [])
        
        # è¯„ä¼°æ¨èå‡†ç¡®æ€§
        successful_recommendations = len(set(recommended_tails).intersection(set(actual_outcome)))
        total_recommendations = len(recommended_tails)
        
        if total_recommendations > 0:
            recommendation_accuracy = successful_recommendations / total_recommendations
        else:
            recommendation_accuracy = 0.0
        
        # ç‰¹åˆ«è¯„ä¼°å†·é—¨å¤å‡ºçš„æˆåŠŸç‡
        revival_success = 0.0
        if recommended_tails:
            for tail in recommended_tails:
                if tail in actual_outcome and tail in self.coldness_profiles:
                    profile = self.coldness_profiles[tail]
                    # å¦‚æœæ˜¯çœŸæ­£çš„å†·é—¨å°¾æ•°æˆåŠŸå¤å‡º
                    if profile.coldness_index > 0.6:
                        revival_success += 1.0
            
            revival_success = revival_success / len(recommended_tails)
        
        # æ›´æ–°æˆåŠŸç»Ÿè®¡
        if recommendation_accuracy > 0.6:
            self.successful_revivals += 1
        
        # è®°å½•å­¦ä¹ ç»“æœ
        outcome_record = {
            'timestamp': datetime.now(),
            'prediction': prediction_result,
            'actual_outcome': actual_outcome,
            'recommendation_accuracy': recommendation_accuracy,
            'revival_success_rate': revival_success,
            'successful_tails': list(set(recommended_tails).intersection(set(actual_outcome))),
            'failed_tails': list(set(recommended_tails) - set(actual_outcome))
        }
        
        self.prediction_outcomes.append(outcome_record)
        
        # è‡ªé€‚åº”è°ƒæ•´
        self._adaptive_adjustment(recommendation_accuracy, revival_success)
        
        return {
            'learning_success': True,
            'recommendation_accuracy': recommendation_accuracy,
            'revival_success_rate': revival_success,
            'successful_predictions': self.successful_revivals,
            'total_predictions': self.total_predictions,
            'model_confidence': self.model_confidence,
            'cold_revival_rate': revival_success
        }
    
    def _adaptive_adjustment(self, accuracy: float, revival_success: float):
        """è‡ªé€‚åº”è°ƒæ•´æ¨¡å‹å‚æ•°"""
        
        # è°ƒæ•´å†·é—¨é˜ˆå€¼
        if accuracy > 0.8 and revival_success > 0.7:
            # è¡¨ç°å¾ˆå¥½ï¼Œå¯ä»¥æé«˜å†·é—¨è¦æ±‚
            self.config['coldness_threshold'] = min(0.9, self.config['coldness_threshold'] + 0.02)
        elif accuracy < 0.4:
            # è¡¨ç°ä¸å¥½ï¼Œé™ä½å†·é—¨è¦æ±‚
            self.config['coldness_threshold'] = max(0.5, self.config['coldness_threshold'] - 0.02)
        
        # è°ƒæ•´åçƒ­é—¨æ¿€è¿›ç¨‹åº¦
        if revival_success > 0.6:
            # å†·é—¨æŒ–æ˜æˆåŠŸï¼Œå¯ä»¥æ›´æ¿€è¿›
            self.config['anti_hot_aggressiveness'] = min(0.9, self.config['anti_hot_aggressiveness'] + 0.03)
        elif revival_success < 0.3:
            # å†·é—¨æŒ–æ˜ä¸æˆåŠŸï¼Œå˜ä¿å®ˆ
            self.config['anti_hot_aggressiveness'] = max(0.5, self.config['anti_hot_aggressiveness'] - 0.03)
    
    def _initialize_digging_strategies(self) -> Dict[str, Dict]:
        """åˆå§‹åŒ–å†·é—¨æŒ–æ˜ç­–ç•¥åº“"""
        
        return {
            'extreme_cold_hunter': {
                'type': 'coldness_focused',
                'min_coldness_index': 0.8,
                'description': 'æåº¦å†·é—¨çŒæ‰‹ç­–ç•¥',
                'suitable_conditions': ['long_absence', 'low_frequency']
            },
            'cyclic_revival_tracker': {
                'type': 'timing_focused',
                'cycle_sensitivity': 0.7,
                'description': 'å‘¨æœŸæ€§å¤å‡ºè¿½è¸ªç­–ç•¥',
                'suitable_conditions': ['regular_patterns', 'cyclic_behavior']
            },
            'compensation_psychological': {
                'type': 'psychology_focused',
                'compensation_weight': 0.8,
                'description': 'è¡¥å¿å¿ƒç†åˆ©ç”¨ç­–ç•¥',
                'suitable_conditions': ['extreme_absence', 'player_expectations']
            },
            'anti_hot_contrarian': {
                'type': 'contrarian_focused',
                'contrarian_strength': 0.9,
                'description': 'åçƒ­é—¨å¯¹æŠ—ç­–ç•¥',
                'suitable_conditions': ['hot_number_dominance', 'market_bias']
            },
            'pattern_break_seeker': {
                'type': 'pattern_focused',
                'break_sensitivity': 0.75,
                'description': 'æ¨¡å¼æ‰“ç ´å¯»æ±‚ç­–ç•¥',
                'suitable_conditions': ['established_patterns', 'pattern_fatigue']
            }
        }
    
    def get_model_stats(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
        
        success_rate = self.successful_revivals / self.total_predictions if self.total_predictions > 0 else 0
        
        # å†·é—¨æ¡£æ¡ˆç»Ÿè®¡
        coldness_distribution = defaultdict(int)
        for profile in self.coldness_profiles.values():
            if profile.coldness_index >= 0.8:
                coldness_distribution['extremely_cold'] += 1
            elif profile.coldness_index >= 0.6:
                coldness_distribution['very_cold'] += 1
            elif profile.coldness_index >= 0.4:
                coldness_distribution['moderately_cold'] += 1
            else:
                coldness_distribution['neutral_warm'] += 1
        
        # æœ€è¿‘é¢„æµ‹ç»Ÿè®¡
        recent_outcomes = list(self.prediction_outcomes)[-10:]
        recent_accuracy = np.mean([outcome['recommendation_accuracy'] for outcome in recent_outcomes]) if recent_outcomes else 0
        recent_revival_success = np.mean([outcome['revival_success_rate'] for outcome in recent_outcomes]) if recent_outcomes else 0
        
        return {
            'model_name': 'UnpopularDigger',
            'total_predictions': self.total_predictions,
            'successful_revivals': self.successful_revivals,
            'success_rate': success_rate,
            'model_confidence': self.model_confidence,
            'recent_accuracy': recent_accuracy,
            'recent_revival_success_rate': recent_revival_success,
            'coldness_distribution': dict(coldness_distribution),
            'strategy_count': len(self.digging_strategies),
            'analysis_windows': {k: len(v) for k, v in self.analysis_windows.items()},
            'prediction_history_length': len(self.prediction_outcomes),
            'config_status': {
                'coldness_threshold': self.config['coldness_threshold'],
                'anti_hot_aggressiveness': self.config['anti_hot_aggressiveness'],
                'adaptation_rate': self.config['adaptation_rate']
            }
        }

# è¾…åŠ©åˆ†æç»„ä»¶å®ç°

class ColdnessAnalyzer:
    """å†·é—¨åº¦åˆ†æå™¨"""
    
    def analyze_tail_coldness(self, tail: int, historical_context: List[Dict[str, Any]], 
                             analysis_windows: Dict[str, deque]) -> Dict[str, Any]:
        """åˆ†æå°¾æ•°å†·é—¨åº¦"""
        
        # å¤šæ—¶é—´å°ºåº¦åˆ†æ
        multi_scale_analysis = {}
        
        for window_name, window_data in analysis_windows.items():
            if not window_data:
                continue
                
            window_list = list(window_data)
            
            # è®¡ç®—è¯¥çª—å£å†…çš„ç»Ÿè®¡
            appearances = sum(1 for period in window_list if tail in period.get('tails', []))
            total_periods = len(window_list)
            
            if total_periods > 0:
                frequency = appearances / total_periods
                absence_ratio = 1.0 - frequency
                
                # è®¡ç®—å½“å‰ç¼ºå¸­é•¿åº¦
                current_absence = 0
                for period in window_list:
                    if tail not in period.get('tails', []):
                        current_absence += 1
                    else:
                        break
                
                multi_scale_analysis[window_name] = {
                    'frequency': frequency,
                    'absence_ratio': absence_ratio,
                    'current_absence': current_absence,
                    'appearances': appearances,
                    'total_periods': total_periods
                }
            else:
                multi_scale_analysis[window_name] = {
                    'frequency': 0.0,
                    'absence_ratio': 1.0,
                    'current_absence': 0,
                    'appearances': 0,
                    'total_periods': 0
                }
        
        # ç»¼åˆå†·é—¨åº¦è¯„ä¼°
        coldness_level = self._determine_coldness_level(multi_scale_analysis)
        overall_coldness_score = self._calculate_overall_coldness(multi_scale_analysis)
        
        return {
            'tail': tail,
            'coldness_level': coldness_level,
            'overall_coldness_score': overall_coldness_score,
            'multi_scale_analysis': multi_scale_analysis,
            'analysis_timestamp': datetime.now()
        }
    
    def _determine_coldness_level(self, analysis: Dict[str, Dict]) -> ColdnessLevel:
        """ç¡®å®šå†·é—¨ç­‰çº§"""
        
        # ä½¿ç”¨é•¿æœŸæ•°æ®åˆ¤æ–­
        long_term_data = analysis.get('long_term', {})
        medium_term_data = analysis.get('medium_term', {})
        
        if not long_term_data and not medium_term_data:
            return ColdnessLevel.NEUTRAL
        
        # ä¼˜å…ˆä½¿ç”¨é•¿æœŸæ•°æ®
        primary_data = long_term_data if long_term_data else medium_term_data
        
        absence_ratio = primary_data.get('absence_ratio', 0.5)
        current_absence = primary_data.get('current_absence', 0)
        
        if absence_ratio >= 0.9 and current_absence >= 15:
            return ColdnessLevel.EXTREMELY_COLD
        elif absence_ratio >= 0.8 and current_absence >= 10:
            return ColdnessLevel.VERY_COLD
        elif absence_ratio >= 0.7 and current_absence >= 6:
            return ColdnessLevel.MODERATELY_COLD
        elif absence_ratio >= 0.6 and current_absence >= 3:
            return ColdnessLevel.SLIGHTLY_COLD
        elif absence_ratio < 0.3:
            return ColdnessLevel.WARM
        else:
            return ColdnessLevel.NEUTRAL
    
    def _calculate_overall_coldness(self, analysis: Dict[str, Dict]) -> float:
        """è®¡ç®—ç»¼åˆå†·é—¨åº¦åˆ†æ•°"""
        
        scores = []
        weights = {
            'immediate': 0.15,
            'short_term': 0.25,
            'medium_term': 0.35,
            'long_term': 0.25
        }
        
        for window_name, weight in weights.items():
            if window_name in analysis:
                data = analysis[window_name]
                absence_ratio = data.get('absence_ratio', 0.5)
                current_absence = data.get('current_absence', 0)
                
                # ç»¼åˆè¯„åˆ†
                window_score = (absence_ratio * 0.7 + min(1.0, current_absence / 10.0) * 0.3)
                scores.append(window_score * weight)
        
        return sum(scores) if scores else 0.5

class RevivalPredictor:
    """å¤å‡ºæ—¶æœºé¢„æµ‹å™¨"""
    
    def predict_revival_timing(self, tail: int, coldness_data: Dict[str, Any], 
                              historical_context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """é¢„æµ‹å¤å‡ºæ—¶æœº"""
        
        # è·å–å†·é—¨åº¦æ•°æ®
        coldness_level = coldness_data.get('coldness_level', ColdnessLevel.NEUTRAL)
        multi_scale = coldness_data.get('multi_scale_analysis', {})
        
        # åˆ†æå†å²å¤å‡ºæ¨¡å¼
        revival_patterns = self._analyze_historical_revivals(tail, historical_context)
        
        # è®¡ç®—å¤å‡ºå¼ºåº¦
        revival_strength = self._calculate_revival_strength(coldness_level, revival_patterns, multi_scale)
        
        # è®¡ç®—æ—¶æœºå¾—åˆ†
        timing_score = self._calculate_timing_score(tail, historical_context, revival_patterns)
        
        # ç”Ÿæˆå¤å‡ºä¿¡å·
        revival_signals = self._generate_revival_signals(tail, revival_strength, timing_score, revival_patterns)
        
        return {
            'tail': tail,
            'revival_strength': revival_strength,
            'timing_score': timing_score,
            'revival_signals': revival_signals,
            'historical_patterns': revival_patterns,
            'expected_revival_period': self._estimate_revival_period(revival_patterns, timing_score)
        }
    
    def _analyze_historical_revivals(self, tail: int, historical_context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå†å²å¤å‡ºæ¨¡å¼"""
        
        revival_intervals = []
        last_appearance = -1
        
        for i, period in enumerate(historical_context):
            if tail in period.get('tails', []):
                if last_appearance >= 0:
                    interval = i - last_appearance
                    revival_intervals.append(interval)
                last_appearance = i
        
        if revival_intervals:
            avg_interval = np.mean(revival_intervals)
            std_interval = np.std(revival_intervals)
            min_interval = min(revival_intervals)
            max_interval = max(revival_intervals)
        else:
            avg_interval = 10.0
            std_interval = 5.0
            min_interval = 1
            max_interval = 20
        
        return {
            'revival_intervals': revival_intervals,
            'avg_interval': avg_interval,
            'std_interval': std_interval,
            'min_interval': min_interval,
            'max_interval': max_interval,
            'pattern_consistency': 1.0 - (std_interval / max(avg_interval, 1.0)) if avg_interval > 0 else 0.0
        }
    
    def _calculate_revival_strength(self, coldness_level: ColdnessLevel, 
                                   revival_patterns: Dict, multi_scale: Dict) -> float:
        """è®¡ç®—å¤å‡ºå¼ºåº¦"""
        
        # åŸºäºå†·é—¨ç­‰çº§çš„åŸºç¡€å¼ºåº¦
        level_strength_map = {
            ColdnessLevel.EXTREMELY_COLD: 0.9,
            ColdnessLevel.VERY_COLD: 0.75,
            ColdnessLevel.MODERATELY_COLD: 0.6,
            ColdnessLevel.SLIGHTLY_COLD: 0.45,
            ColdnessLevel.NEUTRAL: 0.3,
            ColdnessLevel.WARM: 0.1
        }
        
        base_strength = level_strength_map.get(coldness_level, 0.3)
        
        # åŸºäºå†å²æ¨¡å¼çš„è°ƒæ•´
        pattern_consistency = revival_patterns.get('pattern_consistency', 0.5)
        pattern_adjustment = pattern_consistency * 0.2
        
        # åŸºäºå¤šæ—¶é—´å°ºåº¦çš„è°ƒæ•´
        long_term_data = multi_scale.get('long_term', {})
        if long_term_data:
            long_term_absence = long_term_data.get('absence_ratio', 0.5)
            long_term_adjustment = long_term_absence * 0.15
        else:
            long_term_adjustment = 0.0
        
        final_strength = base_strength + pattern_adjustment + long_term_adjustment
        return min(1.0, max(0.0, final_strength))
    
    def _calculate_timing_score(self, tail: int, historical_context: List[Dict[str, Any]], 
                               revival_patterns: Dict) -> float:
        """è®¡ç®—æ—¶æœºå¾—åˆ†"""
        
        if not historical_context:
            return 0.5
        
        # è®¡ç®—è‡ªä¸Šæ¬¡å‡ºç°çš„é—´éš”
        periods_since_last = 0
        for period in historical_context:
            if tail not in period.get('tails', []):
                periods_since_last += 1
            else:
                break
        
        # åŸºäºå¹³å‡é—´éš”è®¡ç®—æ—¶æœºæˆç†Ÿåº¦
        avg_interval = revival_patterns.get('avg_interval', 10.0)
        
        if avg_interval > 0:
            timing_maturity = min(1.0, periods_since_last / avg_interval)
        else:
            timing_maturity = 0.5
        
        # è¿‡åº¦å»¶è¿Ÿæƒ©ç½š
        if periods_since_last > avg_interval * 2:
            timing_maturity *= 0.8
        
        return timing_maturity
    
    def _generate_revival_signals(self, tail: int, revival_strength: float, 
                                 timing_score: float, revival_patterns: Dict) -> List[RevivalSignal]:
        """ç”Ÿæˆå¤å‡ºä¿¡å·"""
        
        signals = []
        
        # å¼ºåº¦ä¿¡å·
        if revival_strength > 0.7:
            signals.append(RevivalSignal(
                tail=tail,
                signal_strength=revival_strength,
                signal_type='high_coldness_revival',
                expected_timing=int(revival_patterns.get('avg_interval', 10) * 0.8),
                confidence=revival_strength * 0.9,
                supporting_evidence=['extremely_cold_status', 'long_absence']
            ))
        
        # æ—¶æœºä¿¡å·
        if timing_score > 0.8:
            signals.append(RevivalSignal(
                tail=tail,
                signal_strength=timing_score,
                signal_type='timing_maturity',
                expected_timing=1,
                confidence=timing_score * 0.8,
                supporting_evidence=['interval_analysis', 'timing_maturity']
            ))
        
        # æ¨¡å¼ä¿¡å·
        pattern_consistency = revival_patterns.get('pattern_consistency', 0.0)
        if pattern_consistency > 0.6:
            signals.append(RevivalSignal(
                tail=tail,
                signal_strength=pattern_consistency,
                signal_type='pattern_revival',
                expected_timing=int(revival_patterns.get('avg_interval', 10)),
                confidence=pattern_consistency * 0.7,
                supporting_evidence=['historical_pattern', 'cyclic_behavior']
            ))
        
        return signals
    
    def _estimate_revival_period(self, revival_patterns: Dict, timing_score: float) -> int:
        """ä¼°è®¡å¤å‡ºæœŸæ•°"""
        
        avg_interval = revival_patterns.get('avg_interval', 10.0)
        
        if timing_score > 0.8:
            return 1  # å³å°†å¤å‡º
        elif timing_score > 0.6:
            return int(avg_interval * 0.3)
        else:
            return int(avg_interval * 0.7)

class AntiHotStrategist:
    """åçƒ­é—¨ç­–ç•¥å¸ˆ"""
    
    def analyze_anti_hot_opportunities(self, candidate_tails: List[int], 
                                     historical_context: List[Dict[str, Any]], 
                                     coldness_analysis: Dict[int, Dict]) -> Dict[str, Any]:
        """åˆ†æåçƒ­é—¨æœºä¼š"""
        
        if len(historical_context) < 5:
            return {'overall_strength': 0.0, 'tail_opportunities': {}}
        
        # è¯†åˆ«å½“å‰çƒ­é—¨å°¾æ•°
        hot_tails = self._identify_hot_tails(historical_context)
        
        # åˆ†æåçƒ­é—¨æœºä¼š
        tail_opportunities = {}
        
        for tail in candidate_tails:
            if tail not in hot_tails:  # åªåˆ†æéçƒ­é—¨çš„å€™é€‰å°¾æ•°
                opportunity_strength = self._calculate_anti_hot_opportunity(
                    tail, hot_tails, historical_context, coldness_analysis.get(tail, {})
                )
                
                if opportunity_strength > 0.3:
                    tail_opportunities[tail] = {
                        'opportunity_strength': opportunity_strength,
                        'anti_hot_reasoning': self._generate_anti_hot_reasoning(tail, hot_tails, opportunity_strength)
                    }
        
        # è®¡ç®—æ•´ä½“åçƒ­é—¨å¼ºåº¦
        overall_strength = np.mean(list(opp['opportunity_strength'] for opp in tail_opportunities.values())) if tail_opportunities else 0.0
        
        return {
            'overall_strength': overall_strength,
            'hot_tails_identified': hot_tails,
            'tail_opportunities': tail_opportunities,
            'anti_hot_strategy': self._recommend_anti_hot_strategy(hot_tails, tail_opportunities)
        }
    
    def _identify_hot_tails(self, historical_context: List[Dict[str, Any]]) -> Set[int]:
        """è¯†åˆ«çƒ­é—¨å°¾æ•°"""
        
        # åˆ†ææœ€è¿‘10æœŸ
        recent_periods = historical_context[:10] if len(historical_context) >= 10 else historical_context
        
        tail_counts = defaultdict(int)
        for period in recent_periods:
            for tail in period.get('tails', []):
                tail_counts[tail] += 1
        
        total_periods = len(recent_periods)
        hot_threshold = total_periods * 0.6  # 60%ä»¥ä¸Šå‡ºç°ç‡è§†ä¸ºçƒ­é—¨
        
        hot_tails = {tail for tail, count in tail_counts.items() if count >= hot_threshold}
        
        return hot_tails
    
    def _calculate_anti_hot_opportunity(self, tail: int, hot_tails: Set[int], 
                                      historical_context: List[Dict[str, Any]], 
                                      coldness_data: Dict) -> float:
        """è®¡ç®—åçƒ­é—¨æœºä¼šå¼ºåº¦"""
        
        opportunity_factors = []
        
        # å†·é—¨åº¦å› å­
        coldness_score = coldness_data.get('overall_coldness_score', 0.5)
        opportunity_factors.append(coldness_score * 0.4)
        
        # çƒ­é—¨å¯¹æ¯”å› å­
        if hot_tails:
            hot_contrast = len(hot_tails) / 10.0  # çƒ­é—¨å°¾æ•°å æ¯”
            opportunity_factors.append(hot_contrast * 0.3)
        else:
            opportunity_factors.append(0.0)
        
        # åå‘å¿ƒç†å› å­
        reverse_psychology = self._calculate_reverse_psychology_factor(tail, hot_tails, historical_context)
        opportunity_factors.append(reverse_psychology * 0.3)
        
        return sum(opportunity_factors)
    
    def _calculate_reverse_psychology_factor(self, tail: int, hot_tails: Set[int], 
                                           historical_context: List[Dict[str, Any]]) -> float:
        """è®¡ç®—åå‘å¿ƒç†å› å­"""
        
        # å¦‚æœçƒ­é—¨å°¾æ•°å¾ˆå¤šï¼Œå†·é—¨å°¾æ•°çš„åå‘å¿ƒç†ä»·å€¼å¢åŠ 
        hot_dominance = len(hot_tails) / 10.0
        
        # å¦‚æœè¯¥å°¾æ•°é•¿æœŸè¢«å¿½è§†ï¼Œåå‘ä»·å€¼å¢åŠ 
        recent_5_periods = historical_context[:5] if len(historical_context) >= 5 else historical_context
        recent_appearances = sum(1 for period in recent_5_periods if tail in period.get('tails', []))
        
        neglect_factor = 1.0 - (recent_appearances / max(len(recent_5_periods), 1))
        
        return (hot_dominance * 0.6 + neglect_factor * 0.4)
    
    def _generate_anti_hot_reasoning(self, tail: int, hot_tails: Set[int], strength: float) -> str:
        """ç”Ÿæˆåçƒ­é—¨æ¨ç†"""
        
        if strength > 0.8:
            return f"å°¾æ•°{tail}å®Œå…¨é¿å¼€çƒ­é—¨åŒºåŸŸ{hot_tails}ï¼Œå…·æœ‰å¼ºåçƒ­é—¨ä»·å€¼"
        elif strength > 0.6:
            return f"å°¾æ•°{tail}ä¸çƒ­é—¨{hot_tails}å½¢æˆå¯¹æ¯”ï¼Œé€‚åˆåçƒ­é—¨ç­–ç•¥"
        else:
            return f"å°¾æ•°{tail}æœ‰ä¸€å®šåçƒ­é—¨æœºä¼š"
    
    def _recommend_anti_hot_strategy(self, hot_tails: Set[int], opportunities: Dict) -> str:
        """æ¨èåçƒ­é—¨ç­–ç•¥"""
        
        if len(hot_tails) >= 4:
            return "aggressive_anti_hot"  # æ¿€è¿›åçƒ­é—¨
        elif len(hot_tails) >= 2:
            return "moderate_anti_hot"    # æ¸©å’Œåçƒ­é—¨
        else:
            return "minimal_anti_hot"     # è½»å¾®åçƒ­é—¨

class ColdPatternDetector:
    """å†·é—¨æ¨¡å¼æ£€æµ‹å™¨"""
    
    def detect_cold_patterns(self, candidate_tails: List[int], 
                           historical_context: List[Dict[str, Any]], 
                           coldness_analysis: Dict[int, Dict]) -> Dict[str, Any]:
        """æ£€æµ‹å†·é—¨æ¨¡å¼"""
        
        if len(historical_context) < 15:
            return {'overall_pattern_strength': 0.0, 'tail_pattern_signals': {}}
        
        tail_pattern_signals = {}
        
        for tail in candidate_tails:
            pattern_signals = self._analyze_tail_patterns(tail, historical_context, coldness_analysis.get(tail, {}))
            
            if pattern_signals['overall_strength'] > 0.3:
                tail_pattern_signals[tail] = pattern_signals
        
        # è®¡ç®—æ•´ä½“æ¨¡å¼å¼ºåº¦
        overall_strength = np.mean([signals['overall_strength'] for signals in tail_pattern_signals.values()]) if tail_pattern_signals else 0.0
        
        return {
            'overall_pattern_strength': overall_strength,
            'tail_pattern_signals': tail_pattern_signals,
            'detected_pattern_types': self._summarize_pattern_types(tail_pattern_signals)
        }
    
    def _analyze_tail_patterns(self, tail: int, historical_context: List[Dict[str, Any]], 
                              coldness_data: Dict) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªå°¾æ•°çš„æ¨¡å¼"""
        
        pattern_strengths = {}
        
        # å‘¨æœŸæ€§æ¨¡å¼æ£€æµ‹
        cyclic_strength = self._detect_cyclic_patterns(tail, historical_context)
        pattern_strengths['cyclic'] = cyclic_strength
        
        # è¡¥å¿æ¨¡å¼æ£€æµ‹
        compensation_strength = self._detect_compensation_patterns(tail, historical_context)
        pattern_strengths['compensation'] = compensation_strength
        
        # æ–­è£‚æ¨¡å¼æ£€æµ‹
        break_strength = self._detect_break_patterns(tail, historical_context)
        pattern_strengths['break'] = break_strength
        
        # ç»¼åˆæ¨¡å¼å¼ºåº¦
        overall_strength = np.mean(list(pattern_strengths.values()))
        
        return {
            'overall_strength': overall_strength,
            'pattern_breakdown': pattern_strengths,
            'dominant_pattern': max(pattern_strengths.items(), key=lambda x: x[1])[0] if pattern_strengths else 'none'
        }
    
    def _detect_cyclic_patterns(self, tail: int, historical_context: List[Dict[str, Any]]) -> float:
        """æ£€æµ‹å‘¨æœŸæ€§æ¨¡å¼"""
        
        # è®°å½•å‡ºç°ä½ç½®
        appearance_positions = []
        for i, period in enumerate(historical_context):
            if tail in period.get('tails', []):
                appearance_positions.append(i)
        
        if len(appearance_positions) < 3:
            return 0.0
        
        # è®¡ç®—é—´éš”
        intervals = [appearance_positions[i+1] - appearance_positions[i] for i in range(len(appearance_positions)-1)]
        
        if not intervals:
            return 0.0
        
        # æ£€æµ‹å‘¨æœŸæ€§
        interval_consistency = 1.0 - (np.std(intervals) / max(np.mean(intervals), 1.0))
        
        return max(0.0, interval_consistency)
    
    def _detect_compensation_patterns(self, tail: int, historical_context: List[Dict[str, Any]]) -> float:
        """æ£€æµ‹è¡¥å¿æ¨¡å¼"""
        
        # å¯»æ‰¾é•¿æœŸç¼ºå¸­åçš„å¤å‡ºæ¨¡å¼
        absence_revival_pairs = []
        
        current_absence = 0
        for period in historical_context:
            if tail not in period.get('tails', []):
                current_absence += 1
            else:
                if current_absence > 5:  # ç¼ºå¸­5æœŸä»¥ä¸Šåå¤å‡º
                    absence_revival_pairs.append(current_absence)
                current_absence = 0
        
        if len(absence_revival_pairs) < 2:
            return 0.0
        
        # æ£€æµ‹è¡¥å¿æ¨¡å¼çš„ä¸€è‡´æ€§
        avg_absence = np.mean(absence_revival_pairs)
        consistency = 1.0 - (np.std(absence_revival_pairs) / max(avg_absence, 1.0))
        
        return max(0.0, consistency)
    
    def _detect_break_patterns(self, tail: int, historical_context: List[Dict[str, Any]]) -> float:
        """æ£€æµ‹æ–­è£‚æ¨¡å¼"""
        
        # æ£€æµ‹æ˜¯å¦æ‰“ç ´äº†æŸç§æ—¢å®šæ¨¡å¼
        if len(historical_context) < 10:
            return 0.0
        
        # åˆ†æå‰åŠæ®µå’ŒååŠæ®µçš„å‡ºç°æ¨¡å¼
        mid_point = len(historical_context) // 2
        first_half = historical_context[mid_point:]
        second_half = historical_context[:mid_point]
        
        first_appearances = sum(1 for period in first_half if tail in period.get('tails', []))
        second_appearances = sum(1 for period in second_half if tail in period.get('tails', []))
        
        first_freq = first_appearances / len(first_half) if first_half else 0
        second_freq = second_appearances / len(second_half) if second_half else 0
        
        # é¢‘ç‡å˜åŒ–å¹…åº¦
        frequency_change = abs(first_freq - second_freq)
        
        return min(1.0, frequency_change * 2.0)
    
    def _summarize_pattern_types(self, tail_signals: Dict) -> List[str]:
        """æ€»ç»“æ£€æµ‹åˆ°çš„æ¨¡å¼ç±»å‹"""
        
        pattern_types = set()
        
        for tail_data in tail_signals.values():
            dominant_pattern = tail_data.get('dominant_pattern', 'none')
            if dominant_pattern != 'none':
                pattern_types.add(dominant_pattern)
        
        return list(pattern_types)