# ai_config.py - AIå¼•æ“é…ç½®ç®¡ç†æ¨¡å—

import json
import numpy as np
import os
import math
import warnings
warnings.filterwarnings('ignore')

class AIConfig:
    """AIå¼•æ“é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.setup_dependencies()
    
    def setup_dependencies(self):
        """è®¾ç½®å’Œæ£€æŸ¥æ‰€æœ‰ä¾èµ–"""
        # æ£€æŸ¥NumPyç‰ˆæœ¬å…¼å®¹æ€§
        try:
            numpy_version = np.__version__
            if numpy_version.startswith('2.'):
                print(f"âš ï¸ æ£€æµ‹åˆ°NumPy {numpy_version}ï¼Œå»ºè®®é™çº§åˆ°1.xç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³å…¼å®¹æ€§")
                print("æ‰§è¡Œ: pip install 'numpy<2.0'")
            else:
                print(f"âœ… NumPyç‰ˆæœ¬ {numpy_version} å…¼å®¹")
        except Exception as e:
            print(f"NumPyç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")

        # è®¾ç½®PyTorchç›¸å…³é…ç½®
        self._setup_pytorch()
        
        # è®¾ç½®Riverç›¸å…³é…ç½®
        self._setup_river()
        
        # è®¾ç½®scikit-multiflowç›¸å…³é…ç½®
        self._setup_skmultiflow()
        
        # è®¾ç½®Deep-Riveré…ç½®ï¼ˆå·²ç¦ç”¨ï¼‰
        self._setup_deep_river()
        
        # è®¾ç½®æœ¬åœ°æ¨¡å‹é…ç½®
        self._setup_local_models()
    
    def _setup_pytorch(self):
        """è®¾ç½®PyTorché…ç½®"""
        try:
            import torch
            import torch.nn as nn
            import torch.optim as optim
            import torch.nn.functional as F
            from torch.utils.data import DataLoader, TensorDataset
            from sklearn.preprocessing import MinMaxScaler
            
            self.PYTORCH_AVAILABLE = True
            # ä¿å­˜torchæ¨¡å—ä¸ºå®ä¾‹å±æ€§
            self.torch = torch
            self.nn = nn
            self.optim = optim
            self.F = F
            self.DataLoader = DataLoader
            self.TensorDataset = TensorDataset
            self.MinMaxScaler = MinMaxScaler
            print("âœ… PyTorchå¯¼å…¥æˆåŠŸ")
            
            # æ£€æŸ¥GPUå¯ç”¨æ€§
            try:
                if torch.cuda.is_available():
                    self.DEVICE = torch.device('cuda')
                    print(f"âœ… GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
                else:
                    self.DEVICE = torch.device('cpu')
                    print("â„¹ï¸ ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
            except Exception as e:
                self.DEVICE = torch.device('cpu')
                print(f"âš ï¸ CUDAæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
                
        except ImportError as e:
            self.PYTORCH_AVAILABLE = False
            self.DEVICE = 'cpu'
            self.torch = None
            print(f"âŒ PyTorchå¯¼å…¥å¤±è´¥: {e}")
            if "numpy" in str(e).lower():
                print("ğŸ’¡ è¿™å¯èƒ½æ˜¯NumPyç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·å°è¯•:")
                print("   pip uninstall numpy")
                print("   pip install 'numpy<2.0'")
                print("   pip install torch --force-reinstall")
        except Exception as e:
            self.PYTORCH_AVAILABLE = False
            self.DEVICE = 'cpu'
            self.torch = None
            print(f"âŒ PyTorchåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _setup_river(self):
        """è®¾ç½®Riveré…ç½®"""
        try:
            from river import (
                tree, linear_model, ensemble, drift, metrics, compose, 
                preprocessing, naive_bayes, neighbors, anomaly
            )
            
            # åŸºç¡€åˆ†ç±»å™¨å¯¼å…¥
            from river.tree import HoeffdingTreeClassifier
            
            # æ¼‚ç§»æ£€æµ‹å™¨å¯¼å…¥ï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬ï¼‰
            self.drift_detectors = {}
            try:
                from river.drift import ADWIN
                self.drift_detectors['ADWIN'] = ADWIN
            except ImportError:
                pass
            
            try:
                from river.drift import PageHinkley
                self.drift_detectors['PageHinkley'] = PageHinkley
            except ImportError:
                pass
            
            try:
                from river.drift import KSWIN
                self.drift_detectors['KSWIN'] = KSWIN
            except ImportError:
                pass
            
            try:
                from river.drift import HDDM_A
                self.drift_detectors['HDDM_A'] = HDDM_A
            except ImportError:
                pass
            
            try:
                from river.drift import HDDM_W
                self.drift_detectors['HDDM_W'] = HDDM_W
            except ImportError:
                pass
            
            # é›†æˆå­¦ä¹ å™¨å¯¼å…¥
            self.ensemble_models = {}

            # å°è¯•ä¸åŒçš„å¯¼å…¥è·¯å¾„
            ensemble_imports = [
                ('AdaptiveRandomForestClassifier', ['river.ensemble', 'river.forest']),
                ('OnlineBaggingClassifier', ['river.ensemble']),
                ('StreamingRandomPatchesClassifier', ['river.ensemble']),
                ('BaggingClassifier', ['river.ensemble']),  # å¤‡é€‰åç§°
            ]

            for model_name, import_paths in ensemble_imports:
                for import_path in import_paths:
                    try:
                        module = __import__(import_path, fromlist=[model_name])
                        if hasattr(module, model_name):
                            self.ensemble_models[model_name] = getattr(module, model_name)
                            break
                    except ImportError:
                        continue

            print(f"   å‘ç°é›†æˆæ¨¡å‹: {list(self.ensemble_models.keys())}")
            
            # å°è¯•å¯¼å…¥Riverçš„åŸºç¡€é›†æˆæ¨¡å‹
            try:
                from river.ensemble import BaggingClassifier as RiverBaggingClassifier
                self.ensemble_models['RiverBaggingClassifier'] = RiverBaggingClassifier
                print(f"   âœ“ æˆåŠŸå¯¼å…¥RiveråŸºç¡€è£…è¢‹åˆ†ç±»å™¨")
            except ImportError:
                print(f"   âœ— RiveråŸºç¡€è£…è¢‹åˆ†ç±»å™¨ä¸å¯ç”¨")
            
            # å°è¯•å…¶ä»–å¯èƒ½çš„é›†æˆæ¨¡å‹
            try:
                from river.ensemble import AdaBoostClassifier
                self.ensemble_models['AdaBoostClassifier'] = AdaBoostClassifier
                print(f"   âœ“ æˆåŠŸå¯¼å…¥AdaBooståˆ†ç±»å™¨")
            except ImportError:
                print(f"   âœ— AdaBooståˆ†ç±»å™¨ä¸å¯ç”¨")

            # å°è¯•å¤šç§è£…è¢‹åˆ†ç±»å™¨åç§°ï¼ˆä¸åŒRiverç‰ˆæœ¬å¯èƒ½ä¸åŒï¼‰
            bagging_names = ['BaggingClassifier', 'OnlineBaggingClassifier', 'StreamingBaggingClassifier']
            for bagging_name in bagging_names:
                try:
                    from river.ensemble import BaggingClassifier as RiverBagging
                    self.ensemble_models['OnlineBaggingClassifier'] = RiverBagging
                    print(f"   âœ“ æˆåŠŸå¯¼å…¥è£…è¢‹åˆ†ç±»å™¨: {bagging_name}")
                    break
                except ImportError:
                    try:
                        # å°è¯•ç›´æ¥ä»ensembleå¯¼å…¥
                        ensemble_module = __import__('river.ensemble', fromlist=[bagging_name])
                        if hasattr(ensemble_module, bagging_name):
                            self.ensemble_models['OnlineBaggingClassifier'] = getattr(ensemble_module, bagging_name)
                            print(f"   âœ“ æˆåŠŸå¯¼å…¥è£…è¢‹åˆ†ç±»å™¨: {bagging_name}")
                            break
                    except ImportError:
                        continue
            else:
                print(f"   âš ï¸ æ‰€æœ‰è£…è¢‹åˆ†ç±»å™¨å¯¼å…¥å°è¯•éƒ½å¤±è´¥ï¼Œå°†è·³è¿‡è¯¥æ¨¡å‹")
            
            try:
                from river.ensemble import StreamingRandomPatchesClassifier
                self.ensemble_models['StreamingRandomPatchesClassifier'] = StreamingRandomPatchesClassifier
            except ImportError:
                pass
            
            # çº¿æ€§æ¨¡å‹å¯¼å…¥
            from river.linear_model import LogisticRegression
            self.LogisticRegression = LogisticRegression
            try:
                from river.linear_model import Perceptron
                self.Perceptron = Perceptron
            except ImportError:
                self.Perceptron = LogisticRegression  # fallback
            
            # KNNå¯¼å…¥
            try:
                from river.neighbors import KNNClassifier
                self.KNNClassifier = KNNClassifier
            except ImportError:
                self.KNNClassifier = None
            
            # å…¶ä»–å¿…è¦çš„å¯¼å…¥
            self.HoeffdingTreeClassifier = HoeffdingTreeClassifier
            self.tree = tree
            self.linear_model = linear_model
            self.ensemble = ensemble
            self.drift = drift
            self.metrics = metrics
            self.compose = compose
            self.preprocessing = preprocessing
            self.naive_bayes = naive_bayes
            self.neighbors = neighbors
            self.anomaly = anomaly
            
            self.RIVER_AVAILABLE = True
            print("âœ… Riveråœ¨çº¿å­¦ä¹ åº“å¯¼å…¥æˆåŠŸ")
            print(f"   å¯ç”¨æ¼‚ç§»æ£€æµ‹å™¨: {list(self.drift_detectors.keys())}")
            print(f"   å¯ç”¨é›†æˆæ¨¡å‹: {list(self.ensemble_models.keys())}")
            print(f"   âš ï¸ å·²ç¦ç”¨RiveråŸç”Ÿæœ´ç´ è´å¶æ–¯ï¼Œä½¿ç”¨æœ¬åœ°å®ç°æ›¿ä»£")
            
        except ImportError as e:
            self.RIVER_AVAILABLE = False
            print(f"â„¹ï¸ Riveråº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€å®ç°: {e}")
            if "numpy" in str(e).lower():
                print("ğŸ’¡ è¿™å¯èƒ½æ˜¯NumPyç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·å°è¯•:")
                print("   pip install 'numpy<2.0' river --force-reinstall")
            else:
                print("å¦‚éœ€å®Œæ•´åŠŸèƒ½ï¼Œè¯·å®‰è£…Riveråº“: pip install river")
        except Exception as e:
            self.RIVER_AVAILABLE = False
            print(f"â„¹ï¸ Riveråº“åŠ è½½å¼‚å¸¸ï¼Œå°†ä½¿ç”¨åŸºç¡€å®ç°: {e}")
    
    def _setup_skmultiflow(self):
        """è®¾ç½®scikit-multiflowé…ç½®"""
        try:
            import importlib
            
            # åŠ¨æ€å¯¼å…¥ä»¥é¿å…IDEé”™è¯¯
            skmultiflow_trees = importlib.import_module('skmultiflow.trees')
            skmultiflow_drift = importlib.import_module('skmultiflow.drift_detection')
            skmultiflow_lazy = importlib.import_module('skmultiflow.lazy')
            skmultiflow_ensemble = importlib.import_module('skmultiflow.ensemble')
            
            # è·å–éœ€è¦çš„ç±»
            self.SKMHoeffdingTree = getattr(skmultiflow_trees, 'HoeffdingTreeClassifier')
            self.SKMHoeffdingAdaptive = getattr(skmultiflow_trees, 'HoeffdingAdaptiveTreeClassifier')
            self.ExtremelyFastDecisionTreeClassifier = getattr(skmultiflow_trees, 'ExtremelyFastDecisionTreeClassifier')
            
            self.SKADWIN = getattr(skmultiflow_drift, 'ADWIN')
            self.DDM = getattr(skmultiflow_drift, 'DDM')
            self.EDDM = getattr(skmultiflow_drift, 'EDDM')
            self.SKPageHinkley = getattr(skmultiflow_drift, 'PageHinkley')
            
            self.SKMKNNClassifier = getattr(skmultiflow_lazy, 'KNNClassifier')
            self.OnlineAdaBoostClassifier = getattr(skmultiflow_ensemble, 'OnlineAdaBoostClassifier')
            self.SKMRandomPatches = getattr(skmultiflow_ensemble, 'StreamingRandomPatchesClassifier')
            
            self.SKMULTIFLOW_AVAILABLE = True
            print("âœ… scikit-multiflowå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            self.SKMULTIFLOW_AVAILABLE = False
            print(f"â„¹ï¸ scikit-multiflowåº“ä¸å¯ç”¨ï¼ˆå¯é€‰ï¼‰")
    
    def _setup_deep_river(self):
        """è®¾ç½®Deep Riveré…ç½®ï¼ˆå·²ç¦ç”¨ï¼‰"""
        self.DEEP_RIVER_AVAILABLE = False
        print("â„¹ï¸ Deep-Riveråº“å·²ç¦ç”¨ï¼Œä½¿ç”¨ç¨³å®šçš„åœ¨çº¿å­¦ä¹ æ¨¡å‹æ›¿ä»£")
    
    def _setup_local_models(self):
        """è®¾ç½®æœ¬åœ°æ¨¡å‹é…ç½®"""
        try:
            from sf import (
                LocalHoeffdingTree, LocalLogisticRegression, LocalNaiveBayes,
                LocalBaggingClassifier, LocalAdaBoostClassifier, LocalDriftDetector,
                LocalStandardScaler, LocalPipeline, LocalHistoricalPatternMatcher,
                MultiLevelDriftDetector, StatisticalDriftDetector,
                EnsembleDriftDetector, DynamicFeatureSelector, FeatureInteractionCombiner,
                TimeSeriesFeatureEnhancer, AdaptiveFeatureWeighter, FeatureQualityAssessor,
                ADWINDriftDetector, PageHinkleyDriftDetector, CUSUMDriftDetector
            )
            self.LOCAL_MODELS_AVAILABLE = True
            
            # å­˜å‚¨æœ¬åœ°æ¨¡å‹ç±»
            self.LocalHoeffdingTree = LocalHoeffdingTree
            self.LocalLogisticRegression = LocalLogisticRegression
            self.LocalNaiveBayes = LocalNaiveBayes
            self.LocalBaggingClassifier = LocalBaggingClassifier
            self.LocalAdaBoostClassifier = LocalAdaBoostClassifier
            self.LocalDriftDetector = LocalDriftDetector
            self.LocalStandardScaler = LocalStandardScaler
            self.LocalPipeline = LocalPipeline
            self.LocalHistoricalPatternMatcher = LocalHistoricalPatternMatcher
            self.MultiLevelDriftDetector = MultiLevelDriftDetector
            self.StatisticalDriftDetector = StatisticalDriftDetector
            self.EnsembleDriftDetector = EnsembleDriftDetector
            self.DynamicFeatureSelector = DynamicFeatureSelector
            self.FeatureInteractionCombiner = FeatureInteractionCombiner
            self.TimeSeriesFeatureEnhancer = TimeSeriesFeatureEnhancer
            self.AdaptiveFeatureWeighter = AdaptiveFeatureWeighter
            self.FeatureQualityAssessor = FeatureQualityAssessor
            self.ADWINDriftDetector = ADWINDriftDetector
            self.PageHinkleyDriftDetector = PageHinkleyDriftDetector
            self.CUSUMDriftDetector = CUSUMDriftDetector
            
            print("âœ… æœ¬åœ°åœ¨çº¿å­¦ä¹ æ¨¡å‹å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            self.LOCAL_MODELS_AVAILABLE = False
            print(f"â„¹ï¸ æœ¬åœ°åœ¨çº¿å­¦ä¹ æ¨¡å‹ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨å®ç°: {e}")
            self._setup_fallback_classes()
        except Exception as e:
            self.LOCAL_MODELS_AVAILABLE = False
            print(f"â„¹ï¸ æœ¬åœ°åœ¨çº¿å­¦ä¹ æ¨¡å‹åŠ è½½å¼‚å¸¸ï¼Œå°†ä½¿ç”¨å¤‡ç”¨å®ç°: {e}")
            self._setup_fallback_classes()
    
    def _setup_fallback_classes(self):
        """è®¾ç½®å¤‡ç”¨ç±»"""
        class EnsembleDriftDetector:
            def __init__(self):
                self.detected = False
            def update(self, error_rate, performance_metrics=None):
                pass
            def get_detailed_report(self):
                return {'ensemble_detected': False, 'individual_detectors': {}}
            def reset(self):
                pass
        
        class FeatureQualityAssessor:
            def __init__(self, assessment_window=50):
                pass
            def assess_feature_quality(self, features, accuracy):
                return {'overall_quality': 0.5, 'recommendations': ['å¤‡ç”¨æ¨¡å¼ï¼šç‰¹å¾å¤„ç†åŠŸèƒ½æœ‰é™']}
        
        self.EnsembleDriftDetector = EnsembleDriftDetector
        self.FeatureQualityAssessor = FeatureQualityAssessor

# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
ai_config = AIConfig()

# å¯¼å‡ºå¸¸ç”¨çš„é…ç½®å˜é‡
PYTORCH_AVAILABLE = ai_config.PYTORCH_AVAILABLE
DEVICE = ai_config.DEVICE
RIVER_AVAILABLE = ai_config.RIVER_AVAILABLE
SKMULTIFLOW_AVAILABLE = ai_config.SKMULTIFLOW_AVAILABLE
DEEP_RIVER_AVAILABLE = ai_config.DEEP_RIVER_AVAILABLE
LOCAL_MODELS_AVAILABLE = ai_config.LOCAL_MODELS_AVAILABLE

# === ç‰¹æ®Šæ¨¡å‹é…ç½®ç®¡ç† ===

class SpecialModelsConfig:
    """ç‰¹æ®Šæ¨¡å‹é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç‰¹æ®Šæ¨¡å‹é…ç½®"""
        # é»˜è®¤å¯ç”¨çš„ç‰¹æ®Šæ¨¡å‹åˆ—è¡¨
        self.default_enabled_models = [
            'anti_manipulation_banker_behavior',  # åæ“æ§åˆ†æå™¨
            'reverse_psychology_predictor',       # åå‘å¿ƒç†å­¦é¢„æµ‹å™¨
            'unpopular_digger',                   # å†·é—¨æŒ–æ˜å™¨
            'money_flow_analyzer',                # èµ„é‡‘æµå‘åˆ†æå™¨
            'game_theory_strategist',             # åšå¼ˆè®ºç­–ç•¥å™¨  
            'manipulation_timing_detector',       # æ“æ§æ—¶æœºæ£€æµ‹å™¨
            # 'anti_trend_hunter',                # åè¶‹åŠ¿çŒæ‰‹ï¼ˆå¾…å®ç°ï¼‰
            # 'crowd_psychology_analyzer'         # ç¾¤ä½“å¿ƒç†åˆ†æå™¨ï¼ˆå¾…å®ç°ï¼‰
        ]
        
        # åŠ è½½ç”¨æˆ·è‡ªå®šä¹‰é…ç½®
        self.enabled_models = self._load_user_config()
        
        print(f"ğŸ¯ ç‰¹æ®Šæ¨¡å‹é…ç½®åŠ è½½å®Œæˆ")
        print(f"   å¯ç”¨çš„æ¨¡å‹: {self.enabled_models}")
    
    def _load_user_config(self) -> list:
        """åŠ è½½ç”¨æˆ·è‡ªå®šä¹‰é…ç½®"""
        config_file = "special_models_config.json"
        
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    enabled_models = user_config.get('enabled_special_models', self.default_enabled_models)
                    print(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½ç‰¹æ®Šæ¨¡å‹è®¾ç½®: {config_file}")
                    return enabled_models
            else:
                # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
                self._save_default_config(config_file)
                return self.default_enabled_models.copy()
                
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç‰¹æ®Šæ¨¡å‹é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return self.default_enabled_models.copy()
    
    def _save_default_config(self, config_file: str):
        """ä¿å­˜é»˜è®¤é…ç½®æ–‡ä»¶"""
        try:
            default_config = {
                "enabled_special_models": self.default_enabled_models,
                "model_descriptions": {
                    "anti_manipulation_banker_behavior": "åæ“æ§åˆ†æå™¨ - åˆ†æåº„å®¶è¡Œä¸ºæ¨¡å¼",
                    "reverse_psychology_predictor": "åå‘å¿ƒç†å­¦é¢„æµ‹å™¨ - åŸºäºåå‘æ€ç»´çš„é¢„æµ‹",
                    "unpopular_digger": "å†·é—¨æŒ–æ˜å™¨ - å‘ç°è¢«å¿½è§†çš„æœºä¼š",
                    "money_flow_analyzer": "èµ„é‡‘æµå‘åˆ†æå™¨ - åˆ†æè™šæ‹Ÿèµ„é‡‘æµå‘å’Œèµ”ä»˜å‹åŠ›",
                    "game_theory_strategist": "åšå¼ˆè®ºç­–ç•¥å™¨ - åŸºäºåšå¼ˆè®ºçš„å¤šæ–¹åšå¼ˆåˆ†æ",
                    "manipulation_timing_detector": "æ“æ§æ—¶æœºæ£€æµ‹å™¨ - è¯†åˆ«æ“æ§å‘ç”Ÿçš„æ—¶æœº",
                    "anti_trend_hunter": "åè¶‹åŠ¿çŒæ‰‹ - ä¸“é—¨æ‰“ç ´è¶‹åŠ¿çš„é¢„æµ‹",
                    "crowd_psychology_analyzer": "ç¾¤ä½“å¿ƒç†åˆ†æå™¨ - åˆ†æç¾¤ä½“æŠ•æ³¨å¿ƒç†"
                },
                "configuration_notes": [
                    "å¯ä»¥é€šè¿‡ä¿®æ”¹ enabled_special_models åˆ—è¡¨æ¥å¯ç”¨/ç¦ç”¨ç‰¹å®šæ¨¡å‹",
                    "æ¯ä¸ªæ¨¡å‹éƒ½æœ‰å…¶ç‹¬ç‰¹çš„åˆ†æè§’åº¦å’Œç­–ç•¥é€»è¾‘",
                    "å»ºè®®ä¿æŒè‡³å°‘2-3ä¸ªæ¨¡å‹å¯ç”¨ä»¥ç¡®ä¿é¢„æµ‹å¤šæ ·æ€§"
                ]
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ å·²åˆ›å»ºé»˜è®¤ç‰¹æ®Šæ¨¡å‹é…ç½®æ–‡ä»¶: {config_file}")
            
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def is_model_enabled(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return model_name in self.enabled_models
    
    def enable_model(self, model_name: str):
        """å¯ç”¨æ¨¡å‹"""
        if model_name not in self.enabled_models:
            self.enabled_models.append(model_name)
            print(f"âœ… å·²å¯ç”¨ç‰¹æ®Šæ¨¡å‹: {model_name}")
    
    def disable_model(self, model_name: str):
        """ç¦ç”¨æ¨¡å‹"""
        if model_name in self.enabled_models:
            self.enabled_models.remove(model_name)
            print(f"âŒ å·²ç¦ç”¨ç‰¹æ®Šæ¨¡å‹: {model_name}")
    
    def get_enabled_models(self) -> list:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        return self.enabled_models.copy()
    
    def save_current_config(self):
        """ä¿å­˜å½“å‰é…ç½®"""
        config_file = "special_models_config.json"
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            else:
                config = {}
            
            config['enabled_special_models'] = self.enabled_models
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ç‰¹æ®Šæ¨¡å‹é…ç½®å·²ä¿å­˜")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç‰¹æ®Šæ¨¡å‹é…ç½®å¤±è´¥: {e}")

# åˆ›å»ºç‰¹æ®Šæ¨¡å‹é…ç½®å®ä¾‹
special_models_config = SpecialModelsConfig()

# åœ¨ AIConfig ç±»ä¸­æ·»åŠ æ–¹æ³•
def get_enabled_special_models():
    """è·å–å¯ç”¨çš„ç‰¹æ®Šæ¨¡å‹åˆ—è¡¨"""
    return special_models_config.get_enabled_models()

# å°†æ–¹æ³•æ·»åŠ åˆ°å…¨å±€é…ç½®å®ä¾‹
ai_config.get_enabled_special_models = get_enabled_special_models
ai_config.special_models_config = special_models_config

# å¯¼å‡ºç‰¹æ®Šæ¨¡å‹é…ç½®
ENABLED_SPECIAL_MODELS = special_models_config.get_enabled_models()

print(f"ğŸ¯ ç‰¹æ®Šæ¨¡å‹é…ç½®ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
print(f"   å½“å‰å¯ç”¨çš„ç‰¹æ®Šæ¨¡å‹æ•°é‡: {len(ENABLED_SPECIAL_MODELS)}")