# prediction_analyzer.py - é¢„æµ‹åˆ†ææ¨¡å—

from typing import List, Dict, Any, Optional
import numpy as np
from datetime import datetime

class PredictionAnalyzer:
    """é¢„æµ‹åˆ†æå¤„ç†å™¨"""
    
    def __init__(self, fundamental_laws):
        self.fundamental_laws = fundamental_laws
    
    def generate_detailed_prediction_analysis(self, recommended_tails, confidence, 
                                            ensemble_probabilities, all_predictions, data_list, 
                                            model_decision_records=None):
        """ç”Ÿæˆè¯¦ç»†çš„é¢„æµ‹åˆ†æï¼ˆä½¿ç”¨çœŸå®å†³ç­–è®°å½•ï¼‰"""
        try:
            weight_details = []
            analysis_text = []
            
            # è·å–æœ€æ–°ä¸€æœŸå°¾æ•°
            latest_tails = set(data_list[0].get('tails', [])) if data_list else set()
            
            # å®‰å…¨è·å–æŠ•èµ„ä¿¡æ¯
            has_investment_data = hasattr(self, 'current_investments') and bool(getattr(self, 'current_investments', {}))
            print(f"ğŸ” æŠ•èµ„æ•°æ®çŠ¶æ€: {has_investment_data}")
            
            analysis_text.append("ğŸ” AIé¢„æµ‹å†³ç­–è¿‡ç¨‹è¯¦ç»†åˆ†æ")
            analysis_text.append("=" * 50)
            analysis_text.append("")
            analysis_text.append(f"ğŸ“Š åŸºæœ¬ä¿¡æ¯ï¼š")
            analysis_text.append(f"  â€¢ æœ€æ–°ä¸€æœŸåŒ…å«å°¾æ•°ï¼š{sorted(latest_tails)}")
            analysis_text.append(f"  â€¢ å‚ä¸é¢„æµ‹çš„æ¨¡å‹æ•°é‡ï¼š{len(all_predictions)}")
            analysis_text.append(f"  â€¢ æœ€ç»ˆæ¨èå°¾æ•°ï¼š{recommended_tails}")
            analysis_text.append(f"  â€¢ é¢„æµ‹ç½®ä¿¡åº¦ï¼š{confidence:.3f}")
            analysis_text.append("")
            
            # åº”ç”¨4å¤§å®šå¾‹ç­›é€‰ï¼Œåªåˆ†æé€šè¿‡ç­›é€‰çš„å€™é€‰å°¾æ•°
            latest_tails = set(data_list[0].get('tails', [])) if data_list else set()
            
            # åº”ç”¨4å¤§å®šå¾‹ç­›é€‰å€™é€‰å°¾æ•°
            if data_list and latest_tails:
                # è¯†åˆ«éœ€è¦æ’é™¤çš„å°¾æ•°
                trap_tails = self.fundamental_laws.identify_comprehensive_trap_tails(data_list)
                dual_minimum_tails = self.fundamental_laws.identify_dual_minimum_tails(data_list)
                extremely_hot_tails = self.fundamental_laws.identify_extremely_hot_tails(data_list, periods=30, threshold=20)
                
                # è®¡ç®—é€šè¿‡ç­›é€‰çš„å€™é€‰å°¾æ•°
                excluded_tails = trap_tails.union(dual_minimum_tails).union(extremely_hot_tails)
                valid_candidates = latest_tails - excluded_tails
                
                # æ˜¾ç¤ºç­›é€‰è¿‡ç¨‹
                analysis_text.append("ğŸ” å››å¤§å®šå¾‹ç­›é€‰è¿‡ç¨‹ï¼š")
                analysis_text.append(f"  â€¢ æœ€æ–°ä¸€æœŸåŒ…å«å°¾æ•°ï¼š{sorted(latest_tails)}")
                if trap_tails:
                    analysis_text.append(f"  â€¢ å®šå¾‹1æ’é™¤é™·é˜±å°¾æ•°ï¼š{sorted(trap_tails)}")
                if dual_minimum_tails:
                    analysis_text.append(f"  â€¢ å®šå¾‹2æ’é™¤åŒé‡æœ€å°‘å°¾æ•°ï¼š{sorted(dual_minimum_tails)}")
                if extremely_hot_tails:
                    analysis_text.append(f"  â€¢ å®šå¾‹3æ’é™¤æçƒ­å°¾æ•°ï¼š{sorted(extremely_hot_tails)}")
                analysis_text.append(f"  â€¢ é€šè¿‡ç­›é€‰çš„å€™é€‰å°¾æ•°ï¼š{sorted(valid_candidates)}")
                analysis_text.append("")
            else:
                valid_candidates = latest_tails
                analysis_text.append("âš ï¸ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å®šå¾‹ç­›é€‰")
                analysis_text.append("")
            
            # ä¸ºé€šè¿‡ç­›é€‰çš„å€™é€‰å°¾æ•°ç”Ÿæˆè¯¦ç»†åˆ†æ
            all_candidates_analysis = {}
            
            for candidate_tail in valid_candidates:
                analysis_text.append(f"ğŸ¯ å€™é€‰å°¾æ•° {candidate_tail} çš„è¯¦ç»†åˆ†æï¼š")
                analysis_text.append("")
                
                total_weighted_sum = 0.0
                total_weight = 0.0
                candidate_weight_details = []
                
                # åˆ†ææ¯ä¸ªæ¨¡å‹å¯¹è¿™ä¸ªå€™é€‰å°¾æ•°çš„è´¡çŒ®
                for model_key, predictions in all_predictions.items():
                    if candidate_tail in predictions:
                        model_prob = predictions[candidate_tail]
                        # åªä½¿ç”¨æŠ•èµ„æƒé‡ï¼Œä¸å›é€€åˆ°ä¼ ç»Ÿæƒé‡
                        investment_weight = 0.0
                        try:
                            # ä»å¼•æ“å®ä¾‹è·å–å½“å‰æŠ•èµ„ä¿¡æ¯
                            if (hasattr(self, '_engine_ref') and self._engine_ref and 
                                hasattr(self._engine_ref, 'current_weight_investments') and 
                                self._engine_ref.current_weight_investments and 
                                model_key in self._engine_ref.current_weight_investments):
                                investment_weight = self._engine_ref.current_weight_investments[model_key].get(candidate_tail, 0.0)
                            else:
                                # æ²¡æœ‰æŠ•èµ„æƒé‡æ—¶ï¼Œè¯¥æ¨¡å‹ä¸å‚ä¸è¿™ä¸ªå°¾æ•°çš„é¢„æµ‹
                                investment_weight = 0.0
                        except Exception as e:
                            print(f"âš ï¸ è·å–æ¨¡å‹ {model_key} æŠ•èµ„æƒé‡å¤±è´¥: {e}")
                            investment_weight = 0.0  # æ²¡æœ‰æŠ•èµ„å°±æ˜¯0æƒé‡
                        
                        if investment_weight > 0:
                            # åªæœ‰å½“æœ‰æŠ•èµ„æƒé‡æ—¶æ‰è®¡ç®—è´¡çŒ®
                            if investment_weight > 0:
                                weighted_contribution = investment_weight  # ç›´æ¥ä½¿ç”¨æŠ•èµ„æƒé‡ä½œä¸ºè´¡çŒ®
                            else:
                                weighted_contribution = 0.0  # æ²¡æœ‰æŠ•èµ„å°±æ²¡æœ‰è´¡çŒ®
                            total_weighted_sum += weighted_contribution
                            total_weight += investment_weight
                        else:
                            # æ¨¡å‹æ²¡æœ‰æŠ•èµ„è¯¥å°¾æ•°ï¼Œä¸å‚ä¸è®¡ç®—
                            weighted_contribution = 0.0
                        
                        # åˆ†æé€‰æ‹©ç†ç”±
                        reason = self._analyze_model_selection_reason(model_key, candidate_tail, model_prob, data_list, model_decision_records)
                        
                        # åªè®°å½•æŠ•èµ„æƒé‡ä¿¡æ¯
                        if investment_weight > 0:
                            candidate_weight_details.append({
                                'model_name': model_key,
                                'target_tail': candidate_tail,
                                'prediction_probability': model_prob,
                                'investment_weight': investment_weight,
                                'weight_contribution': investment_weight,  # ç›´æ¥ä½¿ç”¨æŠ•èµ„æƒé‡
                                'selection_reason': reason
                            })
                        
                        # åªæ˜¾ç¤ºæœ‰æŠ•èµ„çš„æ¨¡å‹ä¿¡æ¯
                        if investment_weight > 0:
                            model_display = model_key.replace('_', ' ').title()
                            analysis_text.append(f"  ğŸ“ˆ {model_display}:")
                            analysis_text.append(f"     - é¢„æµ‹æ¦‚ç‡ï¼š{model_prob:.3f}")
                            analysis_text.append(f"     - æŠ•èµ„æƒé‡ï¼š{investment_weight:.4f}")
                            analysis_text.append(f"     - æƒé‡è´¡çŒ®ï¼š{investment_weight:.4f}")  # ç›´æ¥ä½¿ç”¨æŠ•èµ„æƒé‡
                            analysis_text.append(f"     - é€‰æ‹©ç†ç”±ï¼š{reason}")
                            analysis_text.append("")
                
                # é›†æˆå†³ç­–è¿‡ç¨‹
                final_probability = total_weighted_sum / total_weight if total_weight > 0 else 0.5
                analysis_text.append(f"âš–ï¸ å°¾æ•° {candidate_tail} é›†æˆå†³ç­–è¿‡ç¨‹ï¼š")
                analysis_text.append(f"  â€¢ æ€»åŠ æƒæ¦‚ç‡ï¼š{total_weighted_sum:.3f}")
                analysis_text.append(f"  â€¢ æ€»æƒé‡ï¼š{total_weight:.3f}")
                analysis_text.append(f"  â€¢ æœ€ç»ˆæ¦‚ç‡ï¼š{final_probability:.3f}")
                
                # åˆ¤æ–­è¯¥å°¾æ•°æ˜¯å¦è¢«é€‰ä¸­
                is_selected = candidate_tail in recommended_tails if recommended_tails else False
                if is_selected:
                    analysis_text.append(f"  âœ… ç»“æœï¼šè¢«é€‰ä¸ºæœ€ç»ˆæ¨è")
                else:
                    analysis_text.append(f"  âŒ ç»“æœï¼šæœªè¢«é€‰ä¸­")
                    # åˆ†ææœªè¢«é€‰ä¸­çš„åŸå› 
                    if recommended_tails:
                        selected_tail = recommended_tails[0]
                        selected_prob = ensemble_probabilities.get(selected_tail, 0.5)
                        candidate_prob = ensemble_probabilities.get(candidate_tail, 0.5)
                        analysis_text.append(f"  ğŸ“Š æœªé€‰ä¸­åŸå› ï¼šæ¦‚ç‡{candidate_prob:.3f} < æ¨èå°¾æ•°{selected_tail}æ¦‚ç‡{selected_prob:.3f}")
                
                analysis_text.append("")
                analysis_text.append("-" * 50)
                analysis_text.append("")
                
                # ä¿å­˜å€™é€‰åˆ†æç»“æœ
                all_candidates_analysis[candidate_tail] = {
                    'weight_details': candidate_weight_details,
                    'final_probability': final_probability,
                    'is_selected': is_selected
                }
            
            # å¦‚æœæœ‰è¢«æ’é™¤çš„å°¾æ•°ï¼Œç®€è¦è¯´æ˜æ’é™¤åŸå› 
            if data_list and latest_tails:
                excluded_tails = latest_tails - valid_candidates
                if excluded_tails:
                    analysis_text.append("ğŸš« è¢«å®šå¾‹æ’é™¤çš„å°¾æ•°ç®€è¦è¯´æ˜ï¼š")
                    analysis_text.append("")
                    
                    for excluded_tail in sorted(excluded_tails):
                        reasons = []
                        if excluded_tail in trap_tails:
                            reasons.append("é™·é˜±å°¾æ•°")
                        if excluded_tail in dual_minimum_tails:
                            reasons.append("åŒé‡æœ€å°‘")
                        if excluded_tail in extremely_hot_tails:
                            reasons.append("æçƒ­å°¾æ•°")
                        
                        analysis_text.append(f"  âŒ å°¾æ•° {excluded_tail}ï¼šè¢«æ’é™¤ï¼ˆ{' + '.join(reasons)}ï¼‰")
                    
                    analysis_text.append("")
                    analysis_text.append("-" * 50)
                    analysis_text.append("")

            # ä½¿ç”¨æ¨èå°¾æ•°çš„æƒé‡è¯¦æƒ…ä½œä¸ºä¸»è¦æ˜¾ç¤ºå†…å®¹
            if recommended_tails:
                target_tail = recommended_tails[0]
                weight_details = all_candidates_analysis.get(target_tail, {}).get('weight_details', [])
            else:
                # å¦‚æœæ²¡æœ‰æ¨èå°¾æ•°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå€™é€‰çš„è¯¦æƒ…
                if all_candidates_analysis:
                    first_candidate = next(iter(all_candidates_analysis.keys()))
                    weight_details = all_candidates_analysis[first_candidate].get('weight_details', [])
                else:
                    weight_details = []
            
            # æ˜¾ç¤ºé€‰æ‹©çš„æ¨èå°¾æ•°çš„è¯¦ç»†åˆ†æ
            if recommended_tails:
                target_tail = recommended_tails[0]
                analysis_text.append(f"ğŸ¯ æœ€ç»ˆæ¨èå°¾æ•° {target_tail} çš„è¯¦ç»†åˆ†æï¼š")
                analysis_text.append("")
                
                if weight_details:
                    total_weighted_sum = 0.0
                    total_weight = 0.0
                    
                    for detail in weight_details:
                        model_prob = detail['prediction_probability']
                        actual_model_weight = detail.get('model_weight', 0.0)  # å®é™…æ¨¡å‹æƒé‡
                        investment_weight = detail.get('investment_weight', 0.0)  # æŠ•èµ„æƒé‡
                        weighted_contribution = detail['weighted_contribution']
                        reason = detail['selection_reason']
                        model_display = detail['model_name'].replace('_', ' ').title()
                        
                        total_weighted_sum += weighted_contribution
                        total_weight += investment_weight if investment_weight > 0 else actual_model_weight
                        
                        # æ·»åŠ åˆ°åˆ†ææ–‡æœ¬
                        analysis_text.append(f"  ğŸ“ˆ {model_display}:")
                        analysis_text.append(f"     - é¢„æµ‹æ¦‚ç‡ï¼š{model_prob:.3f}")
                        analysis_text.append(f"     - æ¨¡å‹æƒé‡ï¼š{actual_model_weight:.4f}")
                        if investment_weight > 0:
                            analysis_text.append(f"     - æŠ•èµ„æƒé‡ï¼š{investment_weight:.4f}")
                            analysis_text.append(f"     - åŠ æƒè´¡çŒ®ï¼š{weighted_contribution:.4f}")
                        else:
                            analysis_text.append(f"     - åŠ æƒè´¡çŒ®ï¼š{weighted_contribution:.4f}ï¼ˆä½¿ç”¨æ¨¡å‹æƒé‡ï¼‰")
                        analysis_text.append(f"     - é€‰æ‹©ç†ç”±ï¼š{reason}")
                        analysis_text.append("")
                    
                    # é›†æˆå†³ç­–è¿‡ç¨‹
                    final_probability = total_weighted_sum / total_weight if total_weight > 0 else 0.5
                    analysis_text.append(f"âš–ï¸ é›†æˆå†³ç­–è¿‡ç¨‹ï¼š")
                    analysis_text.append(f"  â€¢ æ€»åŠ æƒæ¦‚ç‡ï¼š{total_weighted_sum:.3f}")
                    analysis_text.append(f"  â€¢ æ€»æƒé‡ï¼š{total_weight:.3f}")
                    analysis_text.append(f"  â€¢ æœ€ç»ˆæ¦‚ç‡ï¼š{final_probability:.3f}")
                    analysis_text.append("")
                    
                    # åº”ç”¨åº•å±‚å®šå¾‹åˆ†æ
                    analysis_text.append(f"ğŸ“š åº•å±‚å®šå¾‹åº”ç”¨åˆ†æï¼š")
                    self._add_fundamental_law_analysis(analysis_text, data_list, recommended_tails)
                else:
                    analysis_text.append(f"  âš ï¸ æ— è¯¦ç»†çš„æƒé‡ä¿¡æ¯å¯ä¾›åˆ†æ")
                    analysis_text.append("")

            else:
                analysis_text.append("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¨èå°¾æ•°")
                analysis_text.append("")
                analysis_text.append("å¯èƒ½åŸå› åˆ†æï¼š")
                if data_list and latest_tails:
                    excluded_count = len(latest_tails - valid_candidates)
                    if excluded_count == len(latest_tails):
                        analysis_text.append("  â€¢ æ‰€æœ‰æœ€æ–°æœŸå°¾æ•°éƒ½è¢«å››å¤§å®šå¾‹æ’é™¤")
                        analysis_text.append(f"  â€¢ å…±{len(latest_tails)}ä¸ªå°¾æ•°å…¨éƒ¨è¢«æ’é™¤")
                    elif excluded_count > 0:
                        analysis_text.append(f"  â€¢ {excluded_count}/{len(latest_tails)}ä¸ªå°¾æ•°è¢«å®šå¾‹æ’é™¤")
                        analysis_text.append("  â€¢ å‰©ä½™å€™é€‰å°¾æ•°æ¨¡å‹é¢„æµ‹æ¦‚ç‡è¾ƒä½")
                    else:
                        analysis_text.append("  â€¢ é€šè¿‡å®šå¾‹ç­›é€‰çš„å°¾æ•°æ¨¡å‹é¢„æµ‹æ¦‚ç‡éƒ½è¾ƒä½")
                else:
                    analysis_text.append("  â€¢ æ•°æ®ä¸è¶³æˆ–æ— æœ€æ–°æœŸå°¾æ•°")

            # ç”Ÿæˆå†³ç­–æ€»ç»“
            if recommended_tails and weight_details:
                participating_models = len(weight_details)
                avg_probability = sum(d['prediction_probability'] for d in weight_details) / participating_models
                decision_summary = f"å…±{participating_models}ä¸ªæ¨¡å‹å‚ä¸é¢„æµ‹å°¾æ•°{recommended_tails[0]}ï¼Œå¹³å‡é¢„æµ‹æ¦‚ç‡{avg_probability:.3f}ï¼Œæœ€ç»ˆç½®ä¿¡åº¦{confidence:.3f}"
            else:
                decision_summary = "é¢„æµ‹è¿‡ç¨‹æœªäº§ç”Ÿæœ‰æ•ˆç»“æœï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡æˆ–å¢åŠ å†å²æ ·æœ¬"
            
            return {
                'weight_details': weight_details,
                'decision_summary': decision_summary,
                'detailed_analysis': '\n'.join(analysis_text)
            }
            
        except Exception as e:
            print(f"ç”Ÿæˆè¯¦ç»†é¢„æµ‹åˆ†æå¤±è´¥: {e}")
            return {
                'weight_details': [],
                'decision_summary': f"åˆ†æç”Ÿæˆå¤±è´¥ï¼š{str(e)}",
                'detailed_analysis': f"ç”Ÿæˆè¯¦ç»†åˆ†ææ—¶å‡ºé”™ï¼š{str(e)}"
            }
    
    def _analyze_model_selection_reason(self, model_key, target_tail, probability, data_list, decision_records=None):
        """åˆ†ææ¨¡å‹é€‰æ‹©æŸä¸ªå°¾æ•°çš„ç†ç”±ï¼ˆåŸºäºçœŸå®å†³ç­–è®°å½•ï¼‰"""
        try:
            # è·å–è¯¥æ¨¡å‹çš„è¯¦ç»†å†³ç­–è®°å½•
            if decision_records and model_key in decision_records:
                decision_record = decision_records[model_key]
                
                # è·å–è¯¥å°¾æ•°çš„è¯¦ç»†ç†ç”±
                if 'detailed_reasons' in decision_record and target_tail in decision_record['detailed_reasons']:
                    tail_reason = decision_record['detailed_reasons'][target_tail]
                    
                    # å†å²æ¨¡å¼åŒ¹é…ç®—æ³•çš„è¯¦ç»†ç†ç”±
                    if 'pattern_matcher' in model_key.lower():
                        if isinstance(tail_reason, str):
                            return tail_reason
                        else:
                            return tail_reason.get('reason_summary', f"å†å²æ¨¡å¼åŒ¹é…ï¼šæ¦‚ç‡{probability:.3f}")
                    
                    # å…¶ä»–æ¨¡å‹çš„è¯¦ç»†ç†ç”±
                    elif isinstance(tail_reason, dict):
                        # ä¼˜å…ˆä½¿ç”¨è¯¦ç»†åˆ†æ
                        if 'detailed_analysis' in tail_reason:
                            return tail_reason['detailed_analysis']
                        
                        # å¦åˆ™ç»„åˆå…¶ä»–ä¿¡æ¯
                        reason_parts = []
                        if 'reason_summary' in tail_reason:
                            reason_parts.append(tail_reason['reason_summary'])
                        if 'confidence_level' in tail_reason:
                            reason_parts.append(f"ç½®ä¿¡åº¦:{tail_reason['confidence_level']}")
                        if 'probability_source' in tail_reason:
                            reason_parts.append(f"æ¥æº:{tail_reason['probability_source']}")
                        
                        return " | ".join(reason_parts) if reason_parts else f"æ¦‚ç‡é¢„æµ‹:{probability:.3f}"
                    
                    elif isinstance(tail_reason, str):
                        return tail_reason
                
                # å¦‚æœæ²¡æœ‰ç‰¹å®šå°¾æ•°çš„ç†ç”±ï¼Œä½¿ç”¨å†³ç­–è¿‡ç¨‹
                if 'decision_process' in decision_record:
                    process_summary = " -> ".join(decision_record['decision_process'][-2:])  # æœ€åä¸¤ä¸ªæ­¥éª¤
                    return f"{process_summary} | æ¦‚ç‡:{probability:.3f}"
                
                # ä½¿ç”¨åŒ¹é…åˆ†æï¼ˆé’ˆå¯¹å†å²æ¨¡å¼åŒ¹é…ï¼‰
                if 'matching_analysis' in decision_record:
                    matching_analysis = decision_record['matching_analysis']
                    if target_tail in matching_analysis.get('matching_results', {}):
                        tail_result = matching_analysis['matching_results'][target_tail]
                        match_count = tail_result.get('match_count', 0)
                        best_similarity = tail_result.get('best_similarity', 0.0)
                        
                        if match_count > 0:
                            return f"å†å²åŒ¹é…:{match_count}ä¸ªæ¨¡å¼,æœ€é«˜ç›¸ä¼¼åº¦{best_similarity:.3f} | æ¦‚ç‡:{probability:.3f}"
                        else:
                            return f"å†å²åŒ¹é…:æ— åŒ¹é…æ¨¡å¼ | æ¦‚ç‡:{probability:.3f}"
            
            # å›é€€åˆ°åˆ†æå¼ç†ç”±ï¼ˆå½“æ²¡æœ‰è¯¦ç»†è®°å½•æ—¶ï¼‰
            reasons = []
            
            # æ¨¡å‹ç±»å‹ç‰¹å®šçš„åˆ†æ
            if 'pattern_matcher' in model_key.lower():
                reasons.append("å†å²æ¨¡å¼åŒ¹é…ç®—æ³•")
                if probability > 0.6:
                    reasons.append("å‘ç°é«˜ç›¸ä¼¼åº¦å†å²æ¨¡å¼")
                elif probability > 0.4:
                    reasons.append("å‘ç°ä¸­ç­‰ç›¸ä¼¼åº¦å†å²æ¨¡å¼")
                else:
                    reasons.append("æœªå‘ç°è¶³å¤Ÿç›¸ä¼¼çš„å†å²æ¨¡å¼")
            
            elif 'hoeffding' in model_key.lower():
                reasons.append("Hoeffdingå†³ç­–æ ‘åˆ†æ")
                if data_list and len(data_list) > 0:
                    latest_tails = data_list[0].get('tails', [])
                    if target_tail in latest_tails:
                        reasons.append("å†³ç­–æ ‘åˆ¤æ–­å»¶ç»­å½“å‰è¶‹åŠ¿")
                    else:
                        reasons.append("å†³ç­–æ ‘åˆ¤æ–­è¶‹åŠ¿åè½¬")
            
            elif 'logistic' in model_key.lower():
                reasons.append("é€»è¾‘å›å½’åˆ†æ")
                if probability > 0.7:
                    reasons.append("ç‰¹å¾ç»„åˆå¼ºçƒˆæŒ‡å‘è¯¥å°¾æ•°")
                elif probability > 0.5:
                    reasons.append("ç‰¹å¾ç»„åˆå€¾å‘äºè¯¥å°¾æ•°")
                else:
                    reasons.append("ç‰¹å¾ç»„åˆä¸æ”¯æŒè¯¥å°¾æ•°")
            
            elif 'naive_bayes' in model_key.lower():
                reasons.append("æœ´ç´ è´å¶æ–¯æ¦‚ç‡æ¨ç†")
                reasons.append(f"åŸºäºç‰¹å¾ç‹¬ç«‹å‡è®¾è®¡ç®—æ¦‚ç‡{probability:.3f}")
            
            elif 'bagging' in model_key.lower():
                reasons.append("è£…è¢‹é›†æˆå­¦ä¹ ")
                if probability > 0.6:
                    reasons.append("å¤šæ•°å­æ¨¡å‹æŠ•ç¥¨æ”¯æŒ")
                else:
                    reasons.append("å­æ¨¡å‹æŠ•ç¥¨åˆ†æ­§æˆ–ä¸æ”¯æŒ")
            
            elif 'adaboost' in model_key.lower():
                reasons.append("AdaBoostè‡ªé€‚åº”æå‡")
                reasons.append(f"åŠ æƒæŠ•ç¥¨ç»“æœæ¦‚ç‡{probability:.3f}")
            
            else:
                reasons.append("æœºå™¨å­¦ä¹ ç®—æ³•")
                reasons.append(f"æ¨¡å‹è¾“å‡ºæ¦‚ç‡{probability:.3f}")
            
            # åŸºäºæ¦‚ç‡çš„è¡¥å……åˆ†æ
            if probability > 0.8:
                reasons.append("é«˜ç½®ä¿¡åº¦é¢„æµ‹")
            elif probability > 0.6:
                reasons.append("ä¸­é«˜ç½®ä¿¡åº¦é¢„æµ‹")
            elif probability > 0.4:
                reasons.append("ä¸­ç­‰ç½®ä¿¡åº¦é¢„æµ‹")
            else:
                reasons.append("ä½ç½®ä¿¡åº¦é¢„æµ‹")
            
            return " | ".join(reasons)
            
        except Exception as e:
            return f"åˆ†æå¤±è´¥ï¼š{str(e)} | æ¦‚ç‡:{probability:.3f}"
    
    def _add_fundamental_law_analysis(self, analysis_text, data_list, recommended_tails):
        """æ·»åŠ åº•å±‚å®šå¾‹åº”ç”¨åˆ†æ"""
        try:
            if not data_list:
                analysis_text.append("  â€¢ æ•°æ®ä¸è¶³ï¼Œæ— æ³•åº”ç”¨åº•å±‚å®šå¾‹")
                return
            
            latest_tails = set(data_list[0].get('tails', [])) if data_list else set()
            analysis_text.append(f"  â€¢ å®šå¾‹1ï¼ˆæœ€æ–°æœŸç­›é€‰ï¼‰ï¼šä»{sorted(latest_tails)}ä¸­ç­›é€‰")
            
            if len(data_list) >= 30:
                # é™·é˜±å°¾æ•°åˆ†æ
                trap_tails = self.fundamental_laws.identify_comprehensive_trap_tails(data_list)
                if trap_tails:
                    analysis_text.append(f"  â€¢ å®šå¾‹2ï¼ˆæ’é™¤é™·é˜±ï¼‰ï¼šæ’é™¤{sorted(trap_tails)}")
                else:
                    analysis_text.append(f"  â€¢ å®šå¾‹2ï¼ˆæ’é™¤é™·é˜±ï¼‰ï¼šæœªå‘ç°é™·é˜±å°¾æ•°")
                
                # åŒé‡æœ€å°‘åˆ†æ
                dual_minimum = self.fundamental_laws.identify_dual_minimum_tails(data_list)
                if dual_minimum:
                    analysis_text.append(f"  â€¢ å®šå¾‹3ï¼ˆæ’é™¤åŒé‡æœ€å°‘ï¼‰ï¼šæ’é™¤{sorted(dual_minimum)}")
                else:
                    analysis_text.append(f"  â€¢ å®šå¾‹3ï¼ˆæ’é™¤åŒé‡æœ€å°‘ï¼‰ï¼šæœªå‘ç°åŒé‡æœ€å°‘å°¾æ•°")
                
                # æçƒ­å°¾æ•°åˆ†æ
                extremely_hot = self.fundamental_laws.identify_extremely_hot_tails(data_list)
                if extremely_hot:
                    analysis_text.append(f"  â€¢ å®šå¾‹4ï¼ˆæ’é™¤æçƒ­ï¼‰ï¼šæ’é™¤{sorted(extremely_hot)}ï¼ˆ30æœŸâ‰¥20æ¬¡æˆ–10æœŸâ‰¥8æ¬¡ï¼‰")
                else:
                    analysis_text.append(f"  â€¢ å®šå¾‹4ï¼ˆæ’é™¤æçƒ­ï¼‰ï¼šæœªå‘ç°æçƒ­å°¾æ•°ï¼ˆ30æœŸâ‰¥20æ¬¡æˆ–10æœŸâ‰¥8æ¬¡ï¼‰")
            else:
                analysis_text.append(f"  â€¢ æ•°æ®ä¸è¶³30æœŸï¼Œåº•å±‚å®šå¾‹ç®€åŒ–åº”ç”¨")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„ç­›é€‰è¿‡ç¨‹
            if latest_tails:
                analysis_text.append(f"  â€¢ ç­›é€‰è¿‡ç¨‹æ€»ç»“ï¼š")
                trap_tails = self.fundamental_laws.identify_comprehensive_trap_tails(data_list)
                dual_minimum = self.fundamental_laws.identify_dual_minimum_tails(data_list)
                extremely_hot = self.fundamental_laws.identify_extremely_hot_tails(data_list)
                remaining_after_laws = latest_tails - trap_tails - dual_minimum - extremely_hot
                
                for tail in latest_tails:
                    status_parts = []
                    if tail in trap_tails:
                        status_parts.append("é™·é˜±å°¾æ•°")
                    if tail in dual_minimum:
                        status_parts.append("åŒé‡æœ€å°‘")
                    if tail in extremely_hot:
                        status_parts.append("æçƒ­å°¾æ•°")
                    
                    if status_parts:
                        analysis_text.append(f"    - å°¾æ•°{tail}ï¼šè¢«æ’é™¤ï¼ˆ{' + '.join(status_parts)}ï¼‰")
                    else:
                        analysis_text.append(f"    - å°¾æ•°{tail}ï¼šé€šè¿‡å®šå¾‹ç­›é€‰")
                
                if recommended_tails:
                    analysis_text.append(f"  â€¢ æœ€ç»ˆé€‰æ‹©ï¼šä»é€šè¿‡ç­›é€‰çš„{len(remaining_after_laws)}ä¸ªå°¾æ•°ä¸­é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„{recommended_tails[0]}")
                else:
                    analysis_text.append(f"  â€¢ æœ€ç»ˆç»“æœï¼šæ‰€æœ‰å€™é€‰å‡è¢«å®šå¾‹æ’é™¤")
            else:
                analysis_text.append(f"  â€¢ æœ€ç»ˆç»“æœï¼šæ— å€™é€‰å°¾æ•°")
                
        except Exception as e:
            analysis_text.append(f"  â€¢ åº•å±‚å®šå¾‹åˆ†æå¤±è´¥ï¼š{str(e)}")
    
    def generate_model_specific_reason(self, model_name, tail, probability, tail_features, data_list):
        """ä¸ºç‰¹å®šæ¨¡å‹ç”Ÿæˆè¯¦ç»†çš„å†³ç­–ç†ç”±"""
        reasons = []
        
        # åŸºç¡€ä¿¡æ¯
        reasons.append(f"å°¾æ•°{tail}é¢„æµ‹åˆ†æ")
        
        # æ¨¡å‹ç±»å‹ç‰¹å®šåˆ†æ
        if 'hoeffding' in model_name.lower():
            reasons.append("ã€Hoeffdingå†³ç­–æ ‘åˆ†æã€‘")
            
            # åŸºäºç‰¹å¾çš„å†³ç­–è·¯å¾„åˆ†æ
            if tail_features.get('in_latest_period', False):
                reasons.append("â€¢ å†³ç­–è·¯å¾„ï¼šå°¾æ•°åœ¨æœ€æ–°æœŸå‡ºç° â†’ å»¶ç»­è¶‹åŠ¿åˆ¤æ–­")
            else:
                reasons.append("â€¢ å†³ç­–è·¯å¾„ï¼šå°¾æ•°æœªåœ¨æœ€æ–°æœŸå‡ºç° â†’ å›è¡¥è¶‹åŠ¿åˆ¤æ–­")
            
            consecutive = tail_features.get('consecutive_appearances', 0)
            if consecutive >= 2:
                reasons.append(f"â€¢ è¿ç»­æ€§ç‰¹å¾ï¼šè¿ç»­{consecutive}æœŸå‡ºç°ï¼Œæ ‘åˆ¤æ–­ä¸ºæŒç»­è¶‹åŠ¿")
            elif consecutive == 0:
                last_distance = tail_features.get('last_appearance_distance', -1)
                if last_distance > 0:
                    reasons.append(f"â€¢ é—´éš”ç‰¹å¾ï¼šè·ä¸Šæ¬¡å‡ºç°{last_distance}æœŸï¼Œæ ‘åˆ¤æ–­éœ€è¦å›è¡¥")
                else:
                    reasons.append("â€¢ å†·é—¨ç‰¹å¾ï¼šé•¿æœŸæœªå‡ºç°ï¼Œæ ‘å€¾å‘äºå›è¡¥é¢„æµ‹")
            
            recent_freq = tail_features.get('recent_10_frequency', 0)
            if recent_freq > 0.6:
                reasons.append("â€¢ é¢‘ç‡åˆ¤æ–­ï¼šè¿‘æœŸé«˜é¢‘(>60%)ï¼Œæ ‘è®¤ä¸ºåº”ç»§ç»­")
            elif recent_freq < 0.3:
                reasons.append("â€¢ é¢‘ç‡åˆ¤æ–­ï¼šè¿‘æœŸä½é¢‘(<30%)ï¼Œæ ‘å€¾å‘å›è¡¥")
            else:
                reasons.append("â€¢ é¢‘ç‡åˆ¤æ–­ï¼šè¿‘æœŸä¸­ç­‰é¢‘ç‡ï¼Œæ ‘åŸºäºå…¶ä»–ç‰¹å¾å†³ç­–")
                
        elif 'logistic' in model_name.lower():
            reasons.append("ã€é€»è¾‘å›å½’åˆ†æã€‘")
            
            # åŸºäºç‰¹å¾æƒé‡çš„åˆ†æ
            reasons.append("â€¢ ç‰¹å¾æƒé‡è®¡ç®—ï¼š")
            if tail_features.get('in_latest_period', False):
                reasons.append("  - æœ€æ–°æœŸå‡ºç°ç‰¹å¾ï¼šæ­£å‘æƒé‡+0.3")
            else:
                reasons.append("  - æœ€æ–°æœŸæœªå‡ºç°ç‰¹å¾ï¼šè´Ÿå‘æƒé‡-0.2")
                
            recent_freq = tail_features.get('recent_10_frequency', 0)
            if recent_freq > 0.5:
                reasons.append(f"  - è¿‘æœŸé¢‘ç‡ç‰¹å¾({recent_freq:.2f})ï¼šæ­£å‘æƒé‡+{recent_freq*0.4:.2f}")
            else:
                reasons.append(f"  - è¿‘æœŸé¢‘ç‡ç‰¹å¾({recent_freq:.2f})ï¼šè´Ÿå‘æƒé‡-{(1-recent_freq)*0.3:.2f}")
                
            consecutive = tail_features.get('consecutive_appearances', 0)
            if consecutive > 0:
                weight = min(consecutive * 0.15, 0.4)
                reasons.append(f"  - è¿ç»­æ€§ç‰¹å¾({consecutive}æœŸ)ï¼šæ­£å‘æƒé‡+{weight:.2f}")
            
            reasons.append(f"â€¢ Sigmoidå‡½æ•°æ˜ å°„ï¼šçº¿æ€§ç»„åˆ â†’ æ¦‚ç‡{probability:.3f}")
            
        elif 'naive_bayes' in model_name.lower():
            reasons.append("ã€æœ´ç´ è´å¶æ–¯åˆ†æã€‘")
            
            # åŸºäºæ¡ä»¶æ¦‚ç‡çš„åˆ†æ
            reasons.append("â€¢ ç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾ä¸‹çš„æ¦‚ç‡è®¡ç®—ï¼š")
            
            if tail_features.get('in_latest_period', False):
                reasons.append("  - P(é¢„æµ‹=1|æœ€æ–°æœŸå‡ºç°) = 0.7")
            else:
                reasons.append("  - P(é¢„æµ‹=1|æœ€æ–°æœŸæœªå‡ºç°) = 0.3")
            
            recent_count = tail_features.get('recent_5_count', 0)
            if recent_count >= 3:
                reasons.append(f"  - P(é¢„æµ‹=1|è¿‘5æœŸå‡ºç°{recent_count}æ¬¡) = 0.8")
            elif recent_count >= 1:
                reasons.append(f"  - P(é¢„æµ‹=1|è¿‘5æœŸå‡ºç°{recent_count}æ¬¡) = 0.6")
            else:
                reasons.append(f"  - P(é¢„æµ‹=1|è¿‘5æœŸå‡ºç°{recent_count}æ¬¡) = 0.2")
            
            reasons.append(f"â€¢ è´å¶æ–¯å®šç†è®¡ç®—åéªŒæ¦‚ç‡ï¼š{probability:.3f}")
            
        elif 'bagging' in model_name.lower():
            reasons.append("ã€è£…è¢‹é›†æˆåˆ†æã€‘")
            
            # æ¨¡æ‹Ÿå­æ¨¡å‹æŠ•ç¥¨
            base_model_type = "å†³ç­–æ ‘" if "hoeffding" not in model_name else "é€»è¾‘å›å½’"
            voting_details = self._simulate_bagging_votes(tail_features, probability)
            
            reasons.append(f"â€¢ åŸºå­¦ä¹ å™¨ï¼š{base_model_type} x 5ä¸ª")
            reasons.append(f"â€¢ æŠ•ç¥¨ç»“æœï¼š{voting_details['positive_votes']}/5 æ”¯æŒé¢„æµ‹")
            reasons.append(f"â€¢ æŠ•ç¥¨è¯¦æƒ…ï¼š{voting_details['vote_details']}")
            reasons.append(f"â€¢ å¹³å‡æ¦‚ç‡ï¼š{probability:.3f}")
            
        elif 'adaboost' in model_name.lower():
            reasons.append("ã€AdaBooståˆ†æã€‘")
            
            # æ¨¡æ‹ŸåŠ æƒæŠ•ç¥¨
            boost_details = self._simulate_adaboost_weights(tail_features, probability)
            
            reasons.append("â€¢ åŠ æƒæŠ•ç¥¨æœºåˆ¶ï¼š")
            for i, (weight, prediction) in enumerate(boost_details['weighted_votes']):
                vote_str = "æ”¯æŒ" if prediction > 0.5 else "åå¯¹"
                reasons.append(f"  - å¼±å­¦ä¹ å™¨{i+1}ï¼šæƒé‡{weight:.2f} Ã— {vote_str}({prediction:.2f})")
            
            reasons.append(f"â€¢ æœ€ç»ˆåŠ æƒç»“æœï¼š{probability:.3f}")
            
        else:
            reasons.append(f"ã€{model_name.replace('_', ' ').title()}åˆ†æã€‘")
            reasons.append(f"â€¢ æ¨¡å‹è¾“å‡ºæ¦‚ç‡ï¼š{probability:.3f}")
            reasons.append("â€¢ åŸºäºè®­ç»ƒæ•°æ®çš„å¤æ‚ç‰¹å¾ç»„åˆåˆ¤æ–­")
        
        # ç½®ä¿¡åº¦è¯„ä¼°
        if probability > 0.7:
            reasons.append(f"â€¢ ç½®ä¿¡åº¦è¯„ä¼°ï¼šé«˜ç½®ä¿¡åº¦({probability:.3f}) - å¼ºçƒˆæ¨è")
        elif probability > 0.6:
            reasons.append(f"â€¢ ç½®ä¿¡åº¦è¯„ä¼°ï¼šä¸­é«˜ç½®ä¿¡åº¦({probability:.3f}) - æ¨è")
        elif probability > 0.4:
            reasons.append(f"â€¢ ç½®ä¿¡åº¦è¯„ä¼°ï¼šä¸­ç­‰ç½®ä¿¡åº¦({probability:.3f}) - ä¸­æ€§")
        else:
            reasons.append(f"â€¢ ç½®ä¿¡åº¦è¯„ä¼°ï¼šä½ç½®ä¿¡åº¦({probability:.3f}) - ä¸æ¨è")
        
        return " | ".join(reasons)
    
    def _simulate_bagging_votes(self, tail_features, final_probability):
        """æ¨¡æ‹Ÿè£…è¢‹é›†æˆçš„æŠ•ç¥¨è¿‡ç¨‹"""
        # åŸºäºæœ€ç»ˆæ¦‚ç‡åæ¨å¯èƒ½çš„æŠ•ç¥¨æƒ…å†µ
        positive_votes = int(final_probability * 5 + 0.5)  # å››èˆäº”å…¥
        positive_votes = max(0, min(5, positive_votes))
        
        vote_details = []
        for i in range(5):
            if i < positive_votes:
                # æ”¯æŒçš„å­æ¨¡å‹
                base_prob = 0.6 + (final_probability - 0.5) * 0.4  # 0.6-0.8ä¹‹é—´
                vote_details.append(f"å­æ¨¡å‹{i+1}:æ”¯æŒ({base_prob:.2f})")
            else:
                # åå¯¹çš„å­æ¨¡å‹
                base_prob = 0.4 - (0.5 - final_probability) * 0.4  # 0.2-0.4ä¹‹é—´
                vote_details.append(f"å­æ¨¡å‹{i+1}:åå¯¹({base_prob:.2f})")
        
        return {
            'positive_votes': positive_votes,
            'vote_details': ' | '.join(vote_details)
        }
    
    def _simulate_adaboost_weights(self, tail_features, final_probability):
        """æ¨¡æ‹ŸAdaBoostçš„åŠ æƒæŠ•ç¥¨è¿‡ç¨‹"""
        # æ¨¡æ‹Ÿ5ä¸ªå¼±å­¦ä¹ å™¨çš„æƒé‡å’Œé¢„æµ‹
        weights = [0.3, 0.25, 0.2, 0.15, 0.1]  # é€’å‡çš„æƒé‡
        
        weighted_votes = []
        for i, weight in enumerate(weights):
            # åŸºäºç‰¹å¾å’Œæœ€ç»ˆæ¦‚ç‡æ¨æµ‹æ¯ä¸ªå¼±å­¦ä¹ å™¨çš„é¢„æµ‹
            if i == 0:  # æƒé‡æœ€é«˜çš„å­¦ä¹ å™¨
                prediction = final_probability + 0.1 if final_probability < 0.9 else 0.9
            elif i == 1:
                prediction = final_probability
            else:
                # åç»­å­¦ä¹ å™¨æœ‰ä¸€å®šéšæœºæ€§
                prediction = final_probability + (0.5 - final_probability) * 0.3
            
            prediction = max(0.0, min(1.0, prediction))
            weighted_votes.append((weight, prediction))
        
        return {'weighted_votes': weighted_votes}